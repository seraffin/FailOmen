{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2monthEvaluationDecisionTree.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "OAA_VXmLa3Jp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Mariusz/2monthEvaluationDecisionTree2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8nx7mo1JCC22",
        "colab_type": "code",
        "outputId": "90297446-65b5-445f-dedd-0970ce90ae4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OAA_VXmLa3Jp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ]
    },
    {
      "metadata": {
        "id": "L7mjN1OX_QZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(additionalPredictions, predictions, refYsupervisor, verbose = False):\n",
        "  \n",
        "  lenght = len(refYsupervisor)\n",
        "\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);\n",
        "\n",
        "  predictionsTemp = predictions.copy()\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "  for i, a in enumerate(predictionsTemp):\n",
        "\n",
        "    if len(failPositions[i]) != 0:\n",
        "      for j in range(1 + additionalPredictions):\n",
        "        argmin = np.argmin(a)\n",
        "        predictionPositions[i].append(argmin)\n",
        "        predictionsTemp[i][argmin] = 1\n",
        "\n",
        "  predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(failPositions) != 0:\n",
        "      predictionHits[i] = count\n",
        "\n",
        "\n",
        "  failsCount = 0\n",
        "  hitsCount = 0\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "    j = 0\n",
        "\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "    failsCount += j\n",
        "    hitsCount += predictionHits[i]\n",
        "\n",
        "  print('additional tests - ', \"%.2f\" % (hitsCount / failsCount * 100), '%')\n",
        "\n",
        "  if verbose == True:\n",
        "    for i in range(lenght):\n",
        "      print(i ,len(failPositions[i]), len(predictionPositions[i]), predictionHits[i], sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zwyfqi6JARhF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Distribution of argmins through all the predictions\n",
        "  \n",
        "def argminsDistribution():\n",
        "  \n",
        "    i = 1\n",
        "    tab = [0] * 542\n",
        "    for a in predictions:\n",
        "      j = 0\n",
        "      for b in a:\n",
        "        if b < 1.0 : j = j + 1\n",
        "\n",
        "      #print (i, '. ', j, np.argmin(a))\n",
        "      tab[np.argmin(a)] += 1\n",
        "      i = i + 1\n",
        "\n",
        "    i = 0\n",
        "    for a in tab:\n",
        "      if a > 0 : print ('position', i, '\\targmin count', a)\n",
        "      i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X35PsbQm79nb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def printFailDistributionStats(y):\n",
        "  \n",
        "  failCount = 0\n",
        "  passCount = 0\n",
        "  failBuildCount = 0\n",
        "\n",
        "  for a in y:\n",
        "    if a[np.argmin(a)] == 0 : failBuildCount += 1\n",
        "    for b in a:\n",
        "      if b == 0 : failCount += 1\n",
        "      if b == 1 : passCount += 1\n",
        "  print ('failBuildCount', failBuildCount)\n",
        "  print ('passBuildCount', len(y) - failBuildCount)\n",
        "  print ('failBuild share ', failBuildCount / len(y) * 100, '%', sep='')\n",
        "  print ('failCount', failCount)\n",
        "  print ('passCount', passCount)\n",
        "  print ('fail share ', failCount / (failCount + passCount) * 100, '%', sep='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMi564-FdxOe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Distributions of argmins through all the predictions\n",
        "\n",
        "def countArgminsDistribution(prediction):\n",
        "  \n",
        "  i = 1\n",
        "  tab = [0] * 542\n",
        "  for a in predictions:\n",
        "    j = 0\n",
        "    for b in a:\n",
        "      if b < 1.0 : j = j + 1\n",
        "\n",
        "    #print (i, '. ', j, np.argmin(a))\n",
        "    tab[np.argmin(a)] += 1\n",
        "    i = i + 1\n",
        "\n",
        "  i = 0\n",
        "  distributed_array = []\n",
        "  for a in tab:\n",
        "    if a > 0 : \n",
        "      print ('position', i, '\\targmin count', a)\n",
        "      distributed_array.append((i,a))\n",
        "    i += 1\n",
        "  create_plot(distributed_array)  \n",
        "  return distributed_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gbNhf1pSTVYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of single member classes positions\n",
        "\n",
        "def listSingleMemberClassesPositions(refY, printFlag):\n",
        "\n",
        "  yList = refY.tolist()\n",
        "  yDistinct = [ele for ind, ele in enumerate(yList) if ele not in yList[:ind]]\n",
        "\n",
        "  classesPopulation = []\n",
        "  singleMemberClassesPositions = []\n",
        "  noSingleMemberClasses = 0\n",
        "\n",
        "  for i, a in enumerate(yDistinct):\n",
        "    population = 0\n",
        "    memberPosition = 0\n",
        "    for j, b in enumerate(yList):\n",
        "      if a == b: \n",
        "        population += 1\n",
        "        memberPosition = j\n",
        "\n",
        "    classesPopulation.append(population)\n",
        "  #  print(i, population)\n",
        "    if population == 1: \n",
        "      noSingleMemberClasses += 1\n",
        "      singleMemberClassesPositions.append(memberPosition)\n",
        "\n",
        "  if printFlag == True: \n",
        "    print(noSingleMemberClasses)\n",
        "  else:\n",
        "    return singleMemberClassesPositions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nfac1udJ9bf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def searchForFailed(yList, withpassed_data = False, share = 1):\n",
        "  changedRowList = []\n",
        "  not_add_passed_data = 0\n",
        "  for row in range (len(yList)):\n",
        "    if 0 in yList[row]:\n",
        "      changedRowList.append(row)\n",
        "      continue\n",
        "    elif withpassed_data == True:\n",
        "      if not not_add_passed_data % share:\n",
        "        changedRowList.append(row)\n",
        "    not_add_passed_data += 1\n",
        "      \n",
        "  return changedRowList\n",
        "\n",
        "def returnFailedData(xList, yList, changedRowList):\n",
        "  xFailed = []\n",
        "  yFailed = []\n",
        "  \n",
        "  for row in changedRowList:\n",
        "    xFailed.append(xList[row])\n",
        "    yFailed.append(yList[row])\n",
        "  xFailed = np.array(xFailed)\n",
        "  yFailed = np.array(yFailed)\n",
        "  return xFailed, yFailed\n",
        "\n",
        "def searchForPassed(yList):\n",
        "  changedRowList = []\n",
        "  for row in range(len(yList)):\n",
        "    if not 0 in yList[row]:\n",
        "      changedRowList.append(row)\n",
        "\n",
        "  return changedRowList\n",
        "\n",
        "def searchForUnchangedFiles(refDatasetFileNumpy, refNoTestSamples):\n",
        "  columnsSum = np.sum(refDatasetFileNumpy, axis=1)\n",
        "  columnsToDelete = []\n",
        "  for i, column in enumerate(columnsSum):\n",
        "    if column == 0: columnsToDelete.append(i + refNoTestSamples)\n",
        "  \n",
        "  for element in columnsToDelete:\n",
        "    print(element, columnsSum[element])\n",
        "  return columnsToDelete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YWPIJOZ-URw1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Double the single member classes for stratified sampling\n",
        "\n",
        "def appendToDataset(refSingleMemberClassesPositions, refDataset):\n",
        "  \n",
        "  newDataset = pd.DataFrame(columns=list(refDataset))\n",
        "  for i, a in enumerate(refSingleMemberClassesPositions):\n",
        "    newDataset = newDataset.append(refDataset.iloc[a, :])\n",
        "  \n",
        "  return refDataset.append(newDataset, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "i_kFoIyfuGxl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkGPUpresence():\n",
        "\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLrYguowbq_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "4hijZ7SlUARA",
        "colab_type": "code",
        "outputId": "9de33e1f-3c72-4e87-e7cd-5d09ecebf554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62-iybQU_Yw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TODO : load data first check no columns, than add headers\n",
        "\n",
        "#Importing dataset\n",
        "noColumnsInFile = 22952\n",
        "noTestsInFile = 402\n",
        "fileColumnsEnd = noColumnsInFile - noTestsInFile\n",
        "headers = list(range(0, noColumnsInFile))\n",
        "dataset = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/dataToML_bin_20190117_new2.csv', names = headers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6q04Vh8a_jf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noTestSamples = 200\n",
        "currnetNoColumns = noColumnsInFile\n",
        "currentFileColumsEnd = currnetNoColumns - noTestsInFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f51XaoKivHFc",
        "colab_type": "code",
        "outputId": "be65626a-faf0-446d-fe9c-367aa10ec3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "datasetTestNumpy = dataset.iloc[noTestSamples:, fileColumnsEnd:noColumnsInFile].values\n",
        "rowsToDelete = searchForPassed(datasetTestNumpy)\n",
        "datasetFileNumpy = dataset.iloc[noTestSamples:, 0:fileColumnsEnd].values\n",
        "columnsToDelete = searchForUnchangedFiles(datasetFileNumpy, noTestSamples)\n",
        "\n",
        "dataset = dataset.drop(rowsToDelete, axis=0)\n",
        "dataset = dataset.drop(columnsToDelete, axis=1)\n",
        "\n",
        "currnetNoColumns = noColumnsInFile - len(columnsToDelete)\n",
        "currentFileColumsEnd = currnetNoColumns - noTestsInFile\n",
        "\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1736, 21136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Fwmq-vtQ960G",
        "colab_type": "code",
        "outputId": "44556e61-c076-4e74-8a5a-86b89959e760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "# Realistic split data set\n",
        "\n",
        "x = dataset.iloc[noTestSamples:, 0:currentFileColumsEnd].values\n",
        "xTest = dataset.iloc[:noTestSamples, 0:currentFileColumsEnd].values\n",
        "y = dataset.iloc[noTestSamples:, currentFileColumsEnd:currnetNoColumns].values\n",
        "yTest = dataset.iloc[:noTestSamples, currentFileColumsEnd:currnetNoColumns].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-05126fff785a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoTestSamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrentFileColumsEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnoTestSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrentFileColumsEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoTestSamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentFileColumsEnd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrnetNoColumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0myTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnoTestSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentFileColumsEnd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrnetNoColumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'noTestSamples' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SljN66tXZC_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Stratified sampling split\n",
        "x = dataset.iloc[:, 0:fileColumnsEnd].values\n",
        "y = dataset.iloc[:, fileColumnsEnd:noColumnsInFile].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMF0cZL3_27r",
        "colab_type": "code",
        "outputId": "f2f4fe41-5b77-4b18-d99c-7579696db100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "printFailDistributionStats(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "failBuildCount 2002\n",
            "passBuildCount 0\n",
            "failBuild share 100.0%\n",
            "failCount 3679\n",
            "passCount 801125\n",
            "fail share 0.457129934741875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BcdkT0ilUJOD",
        "colab_type": "code",
        "outputId": "7a2ba359-a2b1-419d-d39b-7dba946c8239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "cell_type": "code",
      "source": [
        "printFailDistributionStats(yTest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-341d28e10bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintFailDistributionStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'yTest' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bzhEoh59e6Xp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reduce overpopulated class with fully passed builds\n",
        "\n",
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y, withpassed_data=False, share = 1))\n",
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(xReduced, yReduced, test_size = 0.2, random_state=77)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZOiItnfcFrY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare and train model"
      ]
    },
    {
      "metadata": {
        "id": "1px3HvYaLMDo",
        "colab_type": "code",
        "outputId": "1fdf2cff-9f33-442e-f6bc-901a39335876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "xTrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1601, 22550)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "-wMbipli_LD1",
        "colab_type": "code",
        "outputId": "b407cdfc-a2a7-43d0-e55d-457c52a9bc18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(15175, activation=\"sigmoid\", input_dim=fileColumnsEnd, kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(15175, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(noTestsInFile, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(xTrain, yTrain, batch_size = 20, epochs = 15)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1601/1601 [==============================] - 26s 16ms/step - loss: 0.2208 - acc: 0.9340\n",
            "Epoch 2/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0478 - acc: 0.9956\n",
            "Epoch 3/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0370 - acc: 0.9956\n",
            "Epoch 4/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0329 - acc: 0.9956\n",
            "Epoch 5/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0309 - acc: 0.9956\n",
            "Epoch 6/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0297 - acc: 0.9956\n",
            "Epoch 7/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0290 - acc: 0.9956\n",
            "Epoch 8/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0284 - acc: 0.9956\n",
            "Epoch 9/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0281 - acc: 0.9956\n",
            "Epoch 10/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0278 - acc: 0.9956\n",
            "Epoch 11/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0276 - acc: 0.9956\n",
            "Epoch 12/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0274 - acc: 0.9956\n",
            "Epoch 13/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0273 - acc: 0.9956\n",
            "Epoch 14/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0271 - acc: 0.9956\n",
            "Epoch 15/15\n",
            "1601/1601 [==============================] - 16s 10ms/step - loss: 0.0270 - acc: 0.9956\n",
            "--- 249.7993402481079 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wmC2CCxzcaQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "80qYJa28rzE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(xTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83XWARzS7Zmg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Distributions of argmins through all the predictions\n",
        "  \n",
        "def argminsDistribution(): \n",
        "    i = 1\n",
        "    tab = [0] * 542\n",
        "    for a in predictions:\n",
        "      j = 0\n",
        "      for b in a:\n",
        "        if b < 1.0 : j += 1\n",
        "\n",
        "      #print (i, '. ', j, np.argmin(a))\n",
        "      tab[np.argmin(a)] += 1\n",
        "      i = i + 1\n",
        "\n",
        "    i = 0\n",
        "    for a in tab:\n",
        "      if a > 0 : print ('position', i, '\\targmin count', a)\n",
        "      i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69llVn84F0S8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#failsCount()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtK4YeC8oTqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#argminsDistribution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siSMpeyIsNlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate by probability - if the percentage parameter is set to 0.5 than 50% \n",
        "# of predictions will be taken into cosideration. When the strongest prediction \n",
        "# in given build is 0.9 then predictions from 0.9 to 0.95 will be \n",
        "# taken into consideration, if 0.8 than from 0.8 to 0.9\n",
        "\n",
        "def evaluation2(percentage, predictions, refYsupervisor, verbose=False):\n",
        "  \n",
        "  lenght = len(refYsupervisor)\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "  failPredictions = predictions.copy()\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "  predictionHits = [0] * lenght\n",
        "  validPredictionsCount = [0] * lenght\n",
        "\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);\n",
        "  \n",
        "  for i, a in enumerate(predictions):\n",
        "    probabilityLimit = np.amin(a) + ((1 - np.amin(a)) * percentage)\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b <= probabilityLimit: \n",
        "        predictionPositions[i].append(j)\n",
        "        validPredictionsCount[i] += 1\n",
        "        \n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    \n",
        "    for b in a:\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(a) != 0:\n",
        "      predictionHits[i] = count\n",
        "\n",
        "  hitsCount = 0\n",
        "  failsCount = 0\n",
        "  \n",
        "  for i in range(lenght):\n",
        "   # print(predictionHits[i])\n",
        "    hitsCount += predictionHits[i]\n",
        "    failsCount += len(failPositions[i])  \n",
        "\n",
        "  print('Percentage of fails predicted', hitsCount / failsCount * 100, '%',\n",
        "        '//Average of valid predictions', sum(validPredictionsCount)/len(validPredictionsCount))\n",
        "  \n",
        "  if verbose == True:\n",
        "    for i in range(lenght):\n",
        "      print(i ,len(failPositions[i]), len(predictionPositions[i]), predictionHits[i], sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cV8R2p_0gy0f",
        "outputId": "5d4b59be-c024-43b2-eca2-412021d581d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(14):\n",
        "  print(i + 1, ' ', end='')\n",
        "  evaluation(i, predictions, yTest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1  additional tests -  1.70 %\n",
            "2  additional tests -  3.53 %\n",
            "3  additional tests -  5.35 %\n",
            "4  additional tests -  6.69 %\n",
            "5  additional tests -  7.91 %\n",
            "6  additional tests -  9.37 %\n",
            "7  additional tests -  10.34 %\n",
            "8  additional tests -  11.07 %\n",
            "9  additional tests -  12.17 %\n",
            "10  additional tests -  13.14 %\n",
            "11  additional tests -  14.60 %\n",
            "12  additional tests -  15.21 %\n",
            "13  additional tests -  16.18 %\n",
            "14  additional tests -  17.03 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pMYfY33ZLhfo",
        "colab_type": "code",
        "outputId": "4f88344f-005a-4810-f29f-ec382ec36125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(21):\n",
        "  print(round(0.05 * i, 3), ' ', end='')\n",
        "  evaluation2(0.05 * i, predictions, yTest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0  Percentage of fails predicted 1.70316301703163 % //Average of valid predictions 1.0\n",
            "0.05  Percentage of fails predicted 1.70316301703163 % //Average of valid predictions 1.0349127182044888\n",
            "0.1  Percentage of fails predicted 1.9464720194647203 % //Average of valid predictions 1.0897755610972568\n",
            "0.15  Percentage of fails predicted 2.068126520681265 % //Average of valid predictions 1.174563591022444\n",
            "0.2  Percentage of fails predicted 2.5547445255474455 % //Average of valid predictions 1.3690773067331672\n",
            "0.25  Percentage of fails predicted 3.7712895377128954 % //Average of valid predictions 1.9975062344139651\n",
            "0.3  Percentage of fails predicted 5.231143552311435 % //Average of valid predictions 2.8728179551122195\n",
            "0.35  Percentage of fails predicted 5.7177615571776155 % //Average of valid predictions 3.600997506234414\n",
            "0.4  Percentage of fails predicted 7.177615571776156 % //Average of valid predictions 4.261845386533666\n",
            "0.45  Percentage of fails predicted 8.880778588807786 % //Average of valid predictions 5.384039900249377\n",
            "0.5  Percentage of fails predicted 10.948905109489052 % //Average of valid predictions 7.643391521197008\n",
            "0.55  Percentage of fails predicted 12.165450121654501 % //Average of valid predictions 9.256857855361597\n",
            "0.6  Percentage of fails predicted 15.206812652068127 % //Average of valid predictions 11.8428927680798\n",
            "0.65  Percentage of fails predicted 22.019464720194648 % //Average of valid predictions 19.34912718204489\n",
            "0.7  Percentage of fails predicted 28.345498783454985 % //Average of valid predictions 29.134663341645886\n",
            "0.75  Percentage of fails predicted 35.88807785888078 % //Average of valid predictions 41.97256857855361\n",
            "0.8  Percentage of fails predicted 44.28223844282238 % //Average of valid predictions 62.428927680798004\n",
            "0.85  Percentage of fails predicted 57.54257907542579 % //Average of valid predictions 106.65336658354114\n",
            "0.9  Percentage of fails predicted 84.79318734793188 % //Average of valid predictions 231.88029925187033\n",
            "0.95  Percentage of fails predicted 100.0 % //Average of valid predictions 401.20199501246884\n",
            "1.0  Percentage of fails predicted 100.0 % //Average of valid predictions 402.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}