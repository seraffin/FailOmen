{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workingNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Mariusz/workingNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8nx7mo1JCC22",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBw79d2d_PgD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Multiple fails in one build on test set\n",
        "\n",
        "def failsCount():\n",
        "  fala = 0\n",
        "  for i, a in enumerate(yTest):\n",
        "    j = 0\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "    if j > 0 : \n",
        "      print (i, '. ', j)\n",
        "    i = i + 1\n",
        "    fala += j\n",
        "  print (fala)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7mjN1OX_QZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(additionalPredictions):\n",
        "  \n",
        "  lenght = len(yTest)\n",
        "\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(yTest):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);\n",
        "\n",
        "  predictionsTemp = predictions.copy()\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "  for i, a in enumerate(predictionsTemp):\n",
        "\n",
        "    if len(failPositions[i]) != 0:\n",
        "      for j in range(len(failPositions[i]) + additionalPredictions):\n",
        "        argmin = np.argmin(a)\n",
        "        predictionPositions[i].append(argmin)\n",
        "        predictionsTemp[i][argmin] = 1\n",
        "\n",
        "  predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "  #      predictionHits[i].append(predictions[i][c].copy())\n",
        "  #      print(predictions[i][c])\n",
        "  #      print(predictions[i][c])\n",
        "  #      print (b, c)\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(failPositions) != 0:\n",
        "      predictionHits[i].insert(0,count)\n",
        "\n",
        "\n",
        "  failsCount = 0\n",
        "  hitsCount = 0\n",
        "  for i, a in enumerate(yTest):\n",
        "    j = 0\n",
        "\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "    failsCount += j\n",
        "    hitsCount += predictionHits[i][0]\n",
        "\n",
        "  print('Percentage of fails predicted', hitsCount / failsCount * 100, '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zwyfqi6JARhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "b363dc96-cb28-4f2b-e7b2-b0c656058249"
      },
      "cell_type": "code",
      "source": [
        "#Distribution of argmins through all the predictions\n",
        "  \n",
        "def argminsDistribution():\n",
        "  \n",
        "  i = 1\n",
        "  tab = [0] * 542\n",
        "  for a in predictions:\n",
        "    j = 0\n",
        "    for b in a:\n",
        "      if b < 1.0 : j = j + 1\n",
        "\n",
        "    #print (i, '. ', j, np.argmin(a))\n",
        "    tab[np.argmin(a)] += 1\n",
        "    i = i + 1\n",
        "\n",
        "  i = 0\n",
        "  for a in tab:\n",
        "    if a > 0 : print ('position', i, '\\targmin count', a)\n",
        "    i += 1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-7abbd97e3b7e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    i = 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QmLtAzxg3jc8",
        "colab_type": "code",
        "outputId": "af3d182b-d8ce-429b-9da7-1bdcc319ae98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4hijZ7SlUARA",
        "colab_type": "code",
        "outputId": "72e379dc-cbcd-4a39-b8ab-ddf7619316cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fa13Uq6IO1Cd",
        "colab_type": "code",
        "outputId": "11a23f11-2f9b-49c1-ceea-3d429e482c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62-iybQU_Yw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Importing dataset\n",
        "dataset = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/convertDataToML.csv', index_col=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um1FNlpf_zOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, 0:23739].values\n",
        "y = dataset.iloc[:, 23739:24281].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eJvqW2L1bm_w",
        "colab_type": "code",
        "outputId": "d2734a84-9e2a-4c5b-b379-5a64b1c96733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4813, 542)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "E2IOOl-qangL",
        "colab_type": "code",
        "outputId": "c8af9ba2-6af0-4468-977d-fd6097371d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "failCount = 0\n",
        "passCount = 0\n",
        "failBuildCount = 0\n",
        "\n",
        "for a in y:\n",
        "  if a[np.argmin(a)] == 0 : failBuildCount += 1\n",
        "  for b in a:\n",
        "    if b == 0 : failCount += 1\n",
        "    if b == 1 : passCount += 1\n",
        "print (failBuildCount)\n",
        "print (failCount)\n",
        "print (passCount)\n",
        "print (failCount / passCount * 100, '%', sep='')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "632\n",
            "973\n",
            "2607673\n",
            "0.037312960635785236%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Uq6OszKnKgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#labelencoder = LabelEncoder()\n",
        "#y = labelencoder.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8s22Fdfom-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fduCyvWnRv0",
        "colab_type": "code",
        "outputId": "6983b0b6-0772-4d63-f594-b5b6857fd55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#12140\n",
        "model = Sequential()\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(12140, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(12140, activation = \"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "# Adding the output layer\n",
        "model.add(Dense(542, activation=\"sigmoid\", kernel_initializer=\"uniform\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "c76W8TAQRpQs",
        "colab_type": "code",
        "outputId": "2a41d636-708b-4b21-d67f-fd39d2a4175b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(xTrain, yTrain, batch_size = 20, epochs = 15)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "3850/3850 [==============================] - 38s 10ms/step - loss: 0.1503 - acc: 0.9629\n",
            "Epoch 2/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0248 - acc: 0.9996\n",
            "Epoch 3/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0152 - acc: 0.9996\n",
            "Epoch 4/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0113 - acc: 0.9996\n",
            "Epoch 5/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0093 - acc: 0.9996\n",
            "Epoch 6/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0080 - acc: 0.9996\n",
            "Epoch 7/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0071 - acc: 0.9996\n",
            "Epoch 8/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0065 - acc: 0.9996\n",
            "Epoch 9/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0060 - acc: 0.9996\n",
            "Epoch 10/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0056 - acc: 0.9996\n",
            "Epoch 11/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0053 - acc: 0.9996\n",
            "Epoch 12/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0051 - acc: 0.9996\n",
            "Epoch 13/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0049 - acc: 0.9996\n",
            "Epoch 14/15\n",
            "3850/3850 [==============================] - 30s 8ms/step - loss: 0.0047 - acc: 0.9996\n",
            "Epoch 15/15\n",
            "3850/3850 [==============================] - 29s 8ms/step - loss: 0.0045 - acc: 0.9996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a419e3978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "2L3_gtlDY2ve",
        "colab_type": "code",
        "outputId": "52a7760e-32c8-49e0-f834-48e4cbf91231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "lossTest, accTest = model.evaluate(xTest, yTest)\n",
        "\n",
        "print('Test accuracy:', accTest)\n",
        "print('Test loss:', lossTest)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "963/963 [==============================] - 1s 1ms/step\n",
            "Test accuracy: 0.9996206614334883\n",
            "Test loss: 0.00452159610717158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "80qYJa28rzE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(xTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83XWARzS7Zmg",
        "colab_type": "code",
        "outputId": "3075194d-4e4b-494c-fd62-6e993799ce11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "#Distributions of argmins through all the predictions\n",
        "  \n",
        "def argminsDistribution(): \n",
        "  i = 1\n",
        "  tab = [0] * 542\n",
        "  for a in predictions:\n",
        "    j = 0\n",
        "    for b in a:\n",
        "      if b < 1.0 : j = j + 1\n",
        "\n",
        "    #print (i, '. ', j, np.argmin(a))\n",
        "    tab[np.argmin(a)] += 1\n",
        "    i = i + 1\n",
        "\n",
        "  i = 0\n",
        "  for a in tab:\n",
        "    if a > 0 : print ('position', i, '\\targmin count', a)\n",
        "    i += 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "position 71 \targmin count 5\n",
            "position 88 \targmin count 1\n",
            "position 200 \targmin count 80\n",
            "position 260 \targmin count 1\n",
            "position 462 \targmin count 875\n",
            "position 492 \targmin count 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "69llVn84F0S8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#failsCount()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzfX-t8R-Mc-",
        "colab_type": "code",
        "outputId": "bbe886c2-97d4-469b-e5ca-76b9d767bc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "evaluation(15)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32.82828282828283 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7-IkSvRc1lbg",
        "colab_type": "code",
        "outputId": "1e266a3d-8dee-4415-a786-60e647592a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1646
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation function Test\n",
        "position2 = 355\n",
        "\n",
        "predictionsTemp2 = predictions.copy()\n",
        "yTestTemp = yTest.copy()\n",
        "\n",
        "for a in range(1):\n",
        "  testArgmin = np.argmin(yTestTemp[position2])\n",
        "  print(testArgmin)\n",
        "  yTestTemp[position2][testArgmin] = 1\n",
        "\n",
        "for a in range(1 + 3):\n",
        "  predArgmin = np.argmin(predictionsTemp2[position2])\n",
        "  print(predArgmin)\n",
        "  predictionsTemp2[position2][predArgmin] = 1\n",
        "\n",
        "print(predictionsTemp2[0][0])\n",
        "print(predictionsTemp2[10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "462\n",
            "200\n",
            "71\n",
            "140\n",
            "0.9980405\n",
            "[0.9978648  0.9978809  0.9976053  0.9967528  0.99798584 0.9977344\n",
            " 0.9975852  0.9975944  0.9980451  0.99788266 0.9980842  0.99775606\n",
            " 0.99789643 0.99808747 0.9976827  0.99797016 0.9978807  0.9978229\n",
            " 0.9977452  0.99778926 0.9978119  0.9978409  0.9978358  0.99801946\n",
            " 0.9977034  0.99811673 0.99775213 0.9978956  0.99769825 0.99791044\n",
            " 0.99753416 0.99759644 0.9977047  0.9978369  0.9977017  0.9976417\n",
            " 0.9977781  0.99819934 0.9980262  0.99789846 0.99774134 0.9977679\n",
            " 0.9979837  0.9979328  0.9975236  0.99781764 0.99792993 0.99812526\n",
            " 0.997908   0.9976882  0.9978599  0.9978859  0.99795866 0.99798054\n",
            " 0.997693   0.99792224 0.99806756 0.9977679  0.9976847  0.9972428\n",
            " 0.9982498  0.9979348  0.99813676 0.99800617 0.9979634  0.9977806\n",
            " 0.9974722  0.9974522  0.9973978  0.99779606 0.99634844 0.9936807\n",
            " 0.9956417  0.996675   0.99730635 0.99649495 0.99745136 0.9978186\n",
            " 0.9951491  0.9977337  0.99793375 0.9973183  0.9978904  0.9976961\n",
            " 0.9978656  0.9978796  0.9977792  0.99813384 0.9966107  0.9976139\n",
            " 0.9975799  0.9956762  0.99762946 0.99784744 0.9978677  0.9975636\n",
            " 0.99773633 0.99768543 0.99803644 0.9977545  0.9979824  0.99766564\n",
            " 0.9977633  0.99779224 0.99792886 0.99777275 0.9978073  0.9978119\n",
            " 0.9979365  0.9980261  0.9977945  0.997869   0.99773395 0.9977323\n",
            " 0.9977842  0.9978676  0.99725443 0.9964162  0.997486   0.9978701\n",
            " 0.9977203  0.99779034 0.9976756  0.9977729  0.99802387 0.9977373\n",
            " 0.9980976  0.9976382  0.99773765 0.99786216 0.9976674  0.9978795\n",
            " 0.99756277 0.99790823 0.99763083 0.99732375 0.9980413  0.9975376\n",
            " 0.9978612  0.99800843 0.994551   0.99645716 0.9972824  0.9972383\n",
            " 0.9975852  0.9968087  0.99766326 0.9978605  0.99759763 0.99802315\n",
            " 0.99776053 0.9977824  0.998047   0.9975575  0.9977944  0.9976882\n",
            " 0.998092   0.99800164 0.9974367  0.9978179  0.99759007 0.9979972\n",
            " 0.9980367  0.9972582  0.997526   0.99754024 0.99778193 0.99801826\n",
            " 0.9978173  0.99758804 0.99669826 0.9977519  0.99805766 0.9980685\n",
            " 0.99779934 0.9973621  0.9976555  0.9979221  0.99805367 0.9979386\n",
            " 0.9975834  0.9976065  0.9975407  0.99634665 0.9972512  0.9972984\n",
            " 0.99803203 0.99757236 0.9974746  0.99782073 0.9978339  0.99732673\n",
            " 0.9979929  0.9967969  0.99715    0.99687517 0.99748397 0.9965095\n",
            " 0.9971513  0.99785334 0.99389195 0.99783957 0.9972365  0.9977986\n",
            " 0.9975448  0.99773264 0.99782616 0.99783117 0.9978867  0.9977354\n",
            " 0.9974305  0.9977208  0.9979818  0.9979607  0.9979494  0.99750805\n",
            " 0.9971253  0.9980755  0.99745506 0.9980952  0.99769104 0.99692744\n",
            " 0.997535   0.9971312  0.9973213  0.9973621  0.99776006 0.99795544\n",
            " 0.9979108  0.99745363 0.99768627 0.99804723 0.99781966 0.9976548\n",
            " 0.9980008  0.9980247  0.997934   0.9979048  0.99785703 0.9975713\n",
            " 0.99790025 0.99730396 0.9975176  0.99743253 0.997693   0.9975114\n",
            " 0.9975587  0.99713695 0.99790984 0.99721354 0.99768937 0.997633\n",
            " 0.9973628  0.9977575  0.9980563  0.99798596 0.9972562  0.99771357\n",
            " 0.99720687 0.9982126  0.9971841  0.997437   0.9975721  0.9978818\n",
            " 0.9975625  0.998252   0.99783295 0.99785304 0.99762017 0.9982237\n",
            " 0.997823   0.99785185 0.99802077 0.99792445 0.9979146  0.99799806\n",
            " 0.99766517 0.9975278  0.99795216 0.9981268  0.99767095 0.9976851\n",
            " 0.9976229  0.9972983  0.99666363 0.997649   0.99779797 0.99798167\n",
            " 0.9975656  0.99771595 0.9979522  0.9972681  0.9979279  0.99768317\n",
            " 0.9980599  0.99792236 0.9979608  0.9981281  0.997695   0.9980039\n",
            " 0.99795854 0.9974381  0.9976292  0.9976739  0.99777645 0.9978325\n",
            " 0.9975636  0.99736565 0.99743086 0.9975842  0.99788696 0.9979341\n",
            " 0.99775666 0.998071   0.99779165 0.9973049  0.9977678  0.9976649\n",
            " 0.99793965 0.9976217  0.99729556 0.99742246 0.9979455  0.99786\n",
            " 0.99784887 0.99760747 0.9978721  0.9979348  0.9976388  0.99669254\n",
            " 0.99826044 0.9973973  0.99755836 0.9974335  0.99528104 0.997509\n",
            " 0.99783176 0.9969234  0.99739325 0.9976311  0.99736255 0.99735343\n",
            " 0.9980932  0.9978835  0.9973447  0.997375   0.9976987  0.9973212\n",
            " 0.9977581  0.9980122  0.9978217  0.99754494 0.9980203  0.9979652\n",
            " 0.9979382  0.9977164  0.9980908  0.99755967 0.9976043  0.99756\n",
            " 0.9979412  0.99786985 0.997875   0.9975472  0.99777573 0.99784327\n",
            " 0.9977558  0.99786466 0.99826103 0.9977476  0.9978098  0.9977703\n",
            " 0.9977937  0.997959   0.9979085  0.9976756  0.998075   0.99814975\n",
            " 0.99784136 0.99773335 0.99801254 0.99791735 0.99741143 0.9978517\n",
            " 0.9976447  0.9980288  0.9976956  0.9976683  0.9981918  0.9976084\n",
            " 0.9981237  0.9981376  0.9979394  0.99777275 0.99821967 0.9976318\n",
            " 0.9979603  0.9980089  0.99731594 0.99777585 0.9980081  0.9981957\n",
            " 0.99815065 0.997969   0.99792385 0.9980546  0.9979347  0.9979634\n",
            " 0.9976561  0.99766266 0.99815255 0.9978946  0.9978331  0.9975418\n",
            " 0.99771935 0.9978667  0.99802774 0.9978588  0.99807847 0.9978667\n",
            " 0.9976707  0.9976781  0.9974964  0.9978828  0.9979488  0.9977316\n",
            " 0.9978947  0.99791986 0.9977787  0.9974335  0.9979189  0.99738127\n",
            " 0.99783653 0.9977767  0.99767226 0.9978282  0.997888   0.998095\n",
            " 0.99793744 0.99805707 0.997563   0.9977291  0.9978531  0.9977883\n",
            " 0.9978131  0.9976463  0.9977543  0.99749184 0.9979672  0.99740595\n",
            " 0.9979534  0.9978783  0.99799216 0.9979202  0.9978678  0.9979189\n",
            " 0.9978276  0.99785054 0.9976793  0.9977664  0.99785787 0.9982493\n",
            " 0.99178034 0.9973711  0.99809366 0.9977604  0.99739814 0.99785197\n",
            " 0.99752563 0.99673176 0.9967038  0.99771994 0.99790937 0.9976908\n",
            " 0.99778193 0.997769   0.9979734  0.9976292  0.9979153  0.99773836\n",
            " 0.9977944  0.9978537  0.99774843 0.9977836  0.99795926 0.99777454\n",
            " 0.9977464  0.9975217  0.9964264  0.99655235 0.9971578  0.99737096\n",
            " 0.99566734 0.9974298  0.9964636  0.9978204  0.99786264 0.9977228\n",
            " 0.99789786 0.99766856 0.99782276 0.99737275 0.99764144 0.9970913\n",
            " 0.99762756 0.9968382  0.9979126  0.9965239  0.99767846 0.99774384\n",
            " 0.9973871  0.9978485  0.99797446 0.9963025  0.99799395 0.9977319\n",
            " 0.9975904  0.9977585  0.9976713  0.99753416 0.9980908  0.9978655\n",
            " 0.9975562  0.9978934  0.9976005  0.9979644  0.9977724  0.9979315\n",
            " 0.9979267  0.9980562  0.9977591  0.99748445 0.99762684 0.99792933\n",
            " 0.9979652  0.99816245 0.99753594 0.9976229  0.9977354  0.99781066\n",
            " 0.9978994  0.9979095 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}