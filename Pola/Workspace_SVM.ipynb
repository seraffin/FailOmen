{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workspace_SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Pola/Workspace_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8nx7mo1JCC22",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QmLtAzxg3jc8",
        "colab_type": "code",
        "outputId": "27e2c060-976e-45dc-b148-0f577efbb7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4hijZ7SlUARA",
        "colab_type": "code",
        "outputId": "3142b9ce-258d-4dbb-9677-f76cc42e8947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fa13Uq6IO1Cd",
        "colab_type": "code",
        "outputId": "b80d0938-14a2-45a0-81b3-829552688f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!cd '/content/gdrive/My Drive/FailOmen'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62-iybQU_Yw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Importing dataset\n",
        "dataset = pd.read_csv('/content/gdrive/My Drive/FailOmen/convertDataToML.csv', index_col=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um1FNlpf_zOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, 0:23739].values\n",
        "y = dataset.iloc[:, 23739:24281].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2IOOl-qangL",
        "colab_type": "code",
        "outputId": "d7e0ed4c-5f75-4ede-c0bb-3e5fa19a708f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "failCount = 0\n",
        "passCount = 0\n",
        "failBuildCount = 0\n",
        "\n",
        "for a in y:\n",
        "  if a[np.argmin(a)] == 0 : failBuildCount += 1\n",
        "  for b in a:\n",
        "    if b == 0 : failCount += 1\n",
        "    if b == 1 : passCount += 1\n",
        "print (failBuildCount)\n",
        "print (failCount)\n",
        "print (passCount)\n",
        "print (failCount / passCount * 100, '%', sep='')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "632\n",
            "973\n",
            "2607673\n",
            "0.037312960635785236%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RLRrKfR-bL1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MgA1hV7Ljoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **UTILITIES:**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "PlhSJE1hLbl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_distribution(prediction):\n",
        "  #Distributions of argmins through all the predictions\n",
        "  i = 1\n",
        "  tab = [0] * 542\n",
        "  for a in prediction:\n",
        "    j = 0\n",
        "    for b in a:\n",
        "      if b < 1.0 : j = j + 1\n",
        "\n",
        "    #print (i, '. ', j, np.argmin(a))\n",
        "    tab[np.argmin(a)] += 1\n",
        "    i = i + 1\n",
        "\n",
        "  i = 0\n",
        "  number_of_tests =  542\n",
        "  distributed_array = [0 for iterator in range(number_of_tests)]\n",
        "  for a in tab:\n",
        "    if a > 0 : \n",
        "      pass\n",
        "#       print ('position', i, '\\targmin count', a)\n",
        "      distributed_array[i] = a\n",
        "    i += 1\n",
        "#   print (i)\n",
        "  create_plot(range(len(distributed_array)), distributed_array)  \n",
        "  return distributed_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69cYXEP18fPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_plot(x_data, y_data=0):\n",
        "  import matplotlib.pyplot as plt\n",
        "  if y_data == 0:  \n",
        "    unzip = list(zip(*x_data))\n",
        "    x_data, y_data = unzip[0],unzip[1]\n",
        "    print (x_data)\n",
        "    print (\"\\n\", y_data)\n",
        "  \n",
        "  plt.bar(x_data, y_data, align='center', alpha=1, width = 3)\n",
        "  plt.xlabel(\"test no\")\n",
        "  plt.ylabel(\"how many times test was predicted as probably failed\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLkzhHugfFWP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "uwaga, w funkcji ponizej searchForFailed(), w wyborze dodania spassowanych testow do trainig/testing set-a, mino ze podajemy dokladny procent z spassowanych danych jaki chcemy wykorzysatc, procet ten moze sie roznic w rzeczywistosci. Spowodowane jest to warunkiem modulo, np 20% bedzie 20%, 90% bedzie 100% \n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "ECE6fYlxLxZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def searchForFailed(yList, percent_of_passed_data=20, withpassed_data=False): \n",
        "  changedRowList = []\n",
        "  period_counter_for_passedData = 0\n",
        "  for row in range (len(yList)):\n",
        "    if 0 in yList[row]:\n",
        "      changedRowList.append(row)\n",
        "      continue\n",
        "    elif withpassed_data == True:\n",
        "      try:\n",
        "        modulo_arg = int(1/(percent_of_passed_data/100))\n",
        "      except:\n",
        "        withpassed_data = False\n",
        "        continue\n",
        "      if not (period_counter_for_passedData%modulo_arg):\n",
        "        changedRowList.append(row)\n",
        "    period_counter_for_passedData += 1\n",
        "      \n",
        "  return changedRowList\n",
        "\n",
        "def returnFailedData(xList, yList, changedRowList):\n",
        "  xFailed = []\n",
        "  yFailed = []\n",
        "  \n",
        "  for row in changedRowList:\n",
        "    xFailed.append(xList[row])\n",
        "    yFailed.append(yList[row])\n",
        "  xFailed = np.array(xFailed)\n",
        "  yFailed = np.array(yFailed)\n",
        "  return xFailed, yFailed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvZssrz2aDHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def failsCount():\n",
        "  fala = 0\n",
        "  for i, a in enumerate(yTest):\n",
        "    j = 0\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "    if j > 0 : \n",
        "      print (i, '. ', j)\n",
        "    i = i + 1\n",
        "    fala += j\n",
        "  print (fala)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXtv0HaDaEoM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(predictions,additionalPredictions, refYsupervisor):\n",
        "  \n",
        "  lenght = len(refYsupervisor)\n",
        "\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);#spisuje w listach(per commit) pozycje, gdzie sfailowal test [3,78,90, itp]\n",
        "\n",
        "  predictionsTemp = predictions.copy()#tablica list, w ktotej sa przedstawione prawd wystapienia danej labeliki\n",
        "  # todo \n",
        "  #prediction_real byl juz listo po powrotnym mapowaniu, zlozona z testow (czyli ich indeksami 1-542)do sailowania , od najbardziej prawdopodobnych do najmniej \n",
        "  \n",
        "  \n",
        "#   print(predictionsTemp) \n",
        "#   print(type(predictionsTemp))\n",
        "#   print(len(predictionsTemp))\n",
        "#   print(predictionsTemp[0])\n",
        "#   print(predictionsTemp[0][0])\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "  for i, commit in enumerate(predictionsTemp):\n",
        "\n",
        "    if len(failPositions[i]) != 0:#jezeli w danym commicie byl wh jakis blad\n",
        "      for j in range(len(failPositions[i]) + additionalPredictions):#tyle razy co sfailowanych testow + dodatkowe, przez nas zdefiniowane\n",
        "        argmin = np.argmin(commit)# argmin = jest indeksem najmniejsza wartoscia dla predykcji sieci , czyt. indexem najbardziej prawdopodobnej\n",
        "        predictionPositions[i].append(argmin)#umiesc index tej  najbardziej prawdopodobna wartosc, w tab dla danego komitu \n",
        "        predictionsTemp[i][argmin] = 1#nie berz pod uwage juz tej wartosci\n",
        "\n",
        "  predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "  #      predictionHits[i].append(predictions[i][c].copy())\n",
        "  #      print(predictions[i][c])\n",
        "  #      print(predictions[i][c])\n",
        "  #      print (b, c)\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(failPositions) != 0:\n",
        "      predictionHits[i].insert(0,count)\n",
        "\n",
        "\n",
        "  failsCount = 0\n",
        "  hitsCount = 0\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "    j = 0\n",
        "\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "    failsCount += j\n",
        "    hitsCount += predictionHits[i][0]\n",
        "\n",
        "  print('Percentage of fails predicted', hitsCount / failsCount * 100, '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42wJQ7P4izbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def listSingleMemberClassesPositions(refY, printFlag):\n",
        "\n",
        "  yList = refY.tolist()\n",
        "  print (len(yList))\n",
        "  yDistinct = [ele for ind, ele in enumerate(yList) if ele not in yList[:ind]]\n",
        "\n",
        "  classesPopulation = []\n",
        "  singleMemberClassesPositions = []\n",
        "  noSingleMemberClasses = 0\n",
        "\n",
        "  for i, a in enumerate(yDistinct):\n",
        "    population = 0\n",
        "    memberPosition = 0\n",
        "    for j, b in enumerate(yList):\n",
        "      if a == b: \n",
        "        population += 1\n",
        "        memberPosition = j\n",
        "\n",
        "    classesPopulation.append(population)\n",
        "  #  print(i, population)\n",
        "    if population == 1: \n",
        "      noSingleMemberClasses += 1\n",
        "      singleMemberClassesPositions.append(memberPosition)\n",
        "\n",
        "  if printFlag == True: \n",
        "    print(noSingleMemberClasses)\n",
        "  else:\n",
        "    return singleMemberClassesPositions\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIhEbtA9Lr6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mskKtPb0R8CQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **PREPARE DATA**"
      ]
    },
    {
      "metadata": {
        "id": "utDW-luFOIML",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(optional) create only 'failed data'**"
      ]
    },
    {
      "metadata": {
        "id": "BXVlPwABOPnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y,percent_of_passed_data=1,withpassed_data=True))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3aipXpRcVpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_fail_to_pass_ratio(refy):\n",
        "  failCount = 0\n",
        "  passCount = 0\n",
        "  failBuildCount = 0\n",
        "\n",
        "  for a in y:\n",
        "    if a[np.argmin(a)] == 0 : failBuildCount += 1\n",
        "  print (\"To training were used data : \")\n",
        "  print (\"failed builds: \", failBuildCount)\n",
        "  passed_builds = len(refy) - failBuildCount\n",
        "  print('passed builds: ', passed_builds)\n",
        "  try:\n",
        "    print (\"failed to passed  ratio: \", failBuildCount / passed_builds * 100, '%', sep='')\n",
        "  except :\n",
        "    print (\"only failed data\")\n",
        "  \n",
        "  \n",
        "# count_fail_to_pass_ratio(yReduced)\n",
        "  \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmKhHbI4R_sN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ivhO-gnUSEQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PREPARE MODEL"
      ]
    },
    {
      "metadata": {
        "id": "k1UWVSs7xg1-",
        "colab_type": "code",
        "outputId": "214c783b-3205-4b8c-8b4e-6f86bd94b813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import cross_validation, grid_search\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "import numpy\n",
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y,percent_of_passed_data=0,withpassed_data=False))# bez danych spassowanych\n",
        "\n",
        "#################################-- MAPOWANIE MACIERZY NA WEKTOR --#################################################################\n",
        "#select real classes\n",
        "yReduced_temp = yReduced.tolist()\n",
        "real_classes = [(ele) for ind, ele in enumerate(yReduced_temp) if ele not in yReduced_temp[:ind]]#takie klasy mozna wyroznic z supervisora dla danych testowych np [1,0,0,0,1....] inna klasa jest [0,0,0,1,0,1...] itp. \n",
        "\n",
        "\n",
        "# create svm_labels\n",
        "svm_labels = []\n",
        "for i in range(542):\n",
        "  svm_labels.append(float(i))#tworzenie labelek do svm, narazie nie polaczonych z prawdziwymi danymi\n",
        "\n",
        "# create mapper\n",
        "class_mapper = [tuple((real_class, svm_labels[i])) for i, real_class in enumerate(real_classes)]#mapper ktory przypozadkowuje prawdziwym klasom klasy svm np klasa [1,0,0,0,1....] dostaje klase svm 0, itd.\n",
        "\n",
        "\n",
        "# create new supervisor  \n",
        "temp_mapped_supervisor = []  \n",
        "for real_row in yReduced_temp:\n",
        "  for mapper_row in class_mapper:\n",
        "    if real_row == mapper_row[0]:\n",
        "      temp_mapped_supervisor.append(mapper_row[1])# klasy svm przypisane do wiersz danych tesowych np xReduced[0] ma supervisora = 0,  xReduced[123] ma supervisora = 7\n",
        "print(temp_mapped_supervisor)      \n",
        "#map supervisor to numpy.array      \n",
        "mapped_supervisor=numpy.array([numpy.array(xi) for xi in temp_mapped_supervisor])#przekonvertowanie na numpy array\n",
        "# print(mapped_supervisor[123])\n",
        "\n",
        "print(\"tyle wystapien klasy n w danych treningowych: \",len([ele for ele in mapped_supervisor if ele == 155]))\n",
        "print (\"tyle wierszy w danych treningowych: \", len(mapped_supervisor))\n",
        "print (\"tyle klas znaleziono w danych treningowych: \", len(set(mapped_supervisor)))\n",
        "####################################################################################################################################\n",
        "    \n",
        "\n",
        "# xReduced, yReduced = returnFailedData(x, y, searchForFailed(y))\n",
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(xReduced, mapped_supervisor, test_size = 0.2, random_state=77)\n",
        "# print(np.shape(xTrain))\n",
        "# print(np.shape(yTrain))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 2.0, 26.0, 14.0, 27.0, 28.0, 28.0, 28.0, 29.0, 5.0, 28.0, 28.0, 28.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 24.0, 36.0, 37.0, 38.0, 39.0, 40.0, 24.0, 41.0, 42.0, 15.0, 15.0, 43.0, 24.0, 44.0, 15.0, 15.0, 15.0, 44.0, 15.0, 15.0, 45.0, 15.0, 15.0, 44.0, 46.0, 12.0, 20.0, 47.0, 48.0, 49.0, 50.0, 24.0, 51.0, 12.0, 52.0, 24.0, 53.0, 54.0, 55.0, 42.0, 24.0, 31.0, 31.0, 56.0, 57.0, 24.0, 5.0, 24.0, 5.0, 20.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 64.0, 65.0, 32.0, 32.0, 53.0, 53.0, 53.0, 53.0, 53.0, 7.0, 7.0, 7.0, 24.0, 66.0, 24.0, 24.0, 24.0, 9.0, 9.0, 67.0, 67.0, 68.0, 66.0, 66.0, 66.0, 69.0, 33.0, 66.0, 70.0, 66.0, 24.0, 71.0, 72.0, 72.0, 73.0, 24.0, 33.0, 74.0, 24.0, 75.0, 75.0, 66.0, 37.0, 76.0, 31.0, 77.0, 24.0, 24.0, 12.0, 12.0, 12.0, 12.0, 12.0, 78.0, 47.0, 53.0, 53.0, 53.0, 79.0, 52.0, 80.0, 53.0, 81.0, 82.0, 76.0, 76.0, 83.0, 76.0, 83.0, 84.0, 76.0, 24.0, 24.0, 85.0, 85.0, 86.0, 87.0, 85.0, 70.0, 85.0, 86.0, 88.0, 85.0, 70.0, 89.0, 90.0, 91.0, 66.0, 24.0, 66.0, 72.0, 70.0, 85.0, 69.0, 92.0, 85.0, 93.0, 94.0, 85.0, 24.0, 95.0, 96.0, 97.0, 98.0, 99.0, 99.0, 99.0, 99.0, 85.0, 86.0, 98.0, 100.0, 101.0, 90.0, 90.0, 102.0, 85.0, 103.0, 99.0, 56.0, 104.0, 105.0, 106.0, 106.0, 107.0, 108.0, 90.0, 99.0, 53.0, 85.0, 53.0, 109.0, 110.0, 53.0, 65.0, 111.0, 112.0, 113.0, 21.0, 114.0, 85.0, 100.0, 90.0, 34.0, 85.0, 90.0, 115.0, 85.0, 90.0, 92.0, 78.0, 34.0, 116.0, 66.0, 117.0, 34.0, 85.0, 17.0, 118.0, 94.0, 119.0, 120.0, 121.0, 69.0, 122.0, 46.0, 118.0, 56.0, 70.0, 123.0, 124.0, 78.0, 15.0, 125.0, 85.0, 56.0, 56.0, 66.0, 26.0, 78.0, 60.0, 126.0, 126.0, 78.0, 127.0, 128.0, 124.0, 66.0, 23.0, 129.0, 130.0, 131.0, 118.0, 118.0, 121.0, 118.0, 132.0, 100.0, 133.0, 134.0, 135.0, 135.0, 134.0, 136.0, 137.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 142.0, 143.0, 144.0, 144.0, 145.0, 146.0, 145.0, 147.0, 147.0, 148.0, 149.0, 145.0, 150.0, 150.0, 151.0, 145.0, 152.0, 145.0, 153.0, 154.0, 155.0, 152.0, 139.0, 151.0, 156.0, 151.0, 157.0, 158.0, 157.0, 159.0, 160.0, 160.0, 160.0, 160.0, 160.0, 161.0, 162.0, 162.0, 163.0, 162.0, 139.0, 164.0, 165.0, 139.0, 166.0, 167.0, 143.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 143.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 143.0, 143.0, 175.0, 175.0, 181.0, 143.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 152.0, 177.0, 143.0, 188.0, 143.0, 189.0, 133.0, 175.0, 190.0, 191.0, 192.0, 193.0, 133.0, 194.0, 152.0, 195.0, 196.0, 179.0, 152.0, 197.0, 197.0, 175.0, 197.0, 198.0, 199.0, 197.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 175.0, 155.0, 164.0, 208.0, 209.0, 210.0, 175.0, 155.0, 211.0, 212.0, 213.0, 207.0, 207.0, 214.0, 193.0, 144.0, 215.0, 216.0, 217.0, 218.0, 218.0, 218.0, 207.0, 155.0, 219.0, 195.0, 155.0, 195.0, 220.0, 221.0, 165.0, 222.0, 207.0, 207.0, 151.0, 175.0, 216.0, 151.0, 223.0, 224.0, 225.0, 226.0, 207.0, 227.0, 155.0, 155.0, 228.0, 229.0, 229.0, 229.0, 229.0, 229.0, 165.0, 230.0, 231.0, 216.0, 175.0, 232.0, 232.0, 220.0, 155.0, 151.0, 233.0, 234.0, 235.0, 236.0, 235.0, 235.0, 235.0, 235.0, 237.0, 235.0, 236.0, 238.0, 235.0, 235.0, 239.0, 239.0, 239.0, 240.0, 235.0, 235.0, 235.0, 235.0, 151.0, 235.0, 235.0, 151.0, 241.0, 242.0, 242.0, 242.0, 242.0, 242.0, 243.0, 244.0, 241.0, 155.0, 245.0, 216.0, 246.0, 247.0, 248.0, 242.0, 151.0, 207.0, 249.0, 241.0, 189.0, 250.0, 251.0, 155.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 164.0, 259.0, 260.0, 261.0, 262.0, 259.0, 259.0, 199.0, 263.0, 264.0, 265.0, 266.0, 263.0, 267.0, 263.0, 268.0, 269.0, 270.0, 271.0, 197.0, 272.0, 273.0, 160.0, 274.0, 275.0, 276.0, 197.0, 274.0, 277.0, 278.0, 274.0, 191.0, 193.0, 279.0, 273.0, 275.0, 280.0, 155.0, 189.0, 155.0, 155.0, 281.0, 281.0, 189.0, 155.0, 155.0, 155.0, 155.0, 282.0, 283.0, 284.0, 155.0, 155.0, 235.0, 285.0, 255.0, 286.0, 286.0, 286.0, 189.0, 189.0, 287.0, 189.0, 280.0, 288.0, 155.0, 155.0, 155.0, 155.0, 155.0, 188.0, 155.0, 289.0, 289.0, 155.0, 290.0, 291.0, 155.0, 289.0, 155.0, 203.0]\n",
            "tyle wystapien klasy n w danych treningowych:  28\n",
            "tyle wierszy w danych treningowych:  632\n",
            "tyle klas znaleziono w danych treningowych:  292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPRrHzYvypom",
        "colab_type": "code",
        "outputId": "4c0c4db1-3a04-458d-dd76-abea1e1db154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# mala gamma  -  odlegle punkty, od potencjalnej garnicy , maja wplyw na ustawienie granicy (decision boundary)  => moze powodobac niedopasownie\n",
        "# duza gamma -  tylko bliskie punkty, od potencjalnej garnicy , maja wplyw na ustawienie granicy (decision boundary) => moze powodowac overfiting\n",
        "clf = svm.SVC(gamma=0.01,probability=True)#gamma 0.0001\n",
        "# clf = svm.SVC(gamma=0.01,probability=False)#gamma 0.0001\n",
        "clf.fit(xTrain, yTrain) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
              "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "x-oHXGBPzsMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJY1xTCDSLNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tzanoRBUSoWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **TEST MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "80qYJa28rzE0",
        "colab_type": "code",
        "outputId": "a03f53ad-994e-4b81-8323-3059bad9a879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = clf.predict(xTest)\n",
        "# print (predictions[0])\n",
        "# print(len(predictions))\n",
        "# print(predictions)\n",
        "proba_predictions = clf.predict_proba(xTest)\n",
        "print (proba_predictions)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# # Model Accuracy: how often is the classifier correct?\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(xTest,  yTest))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0027397  0.00328256 0.00268905 ... 0.00274635 0.00306844 0.00376391]\n",
            " [0.00262965 0.00263297 0.00277724 ... 0.00268789 0.00269611 0.00271385]\n",
            " [0.00268707 0.00274468 0.00268833 ... 0.00270701 0.00292699 0.00338765]\n",
            " ...\n",
            " [0.0027415  0.00328451 0.00269059 ... 0.00274821 0.00307    0.00376607]\n",
            " [0.00304618 0.00333489 0.00300135 ... 0.0030998  0.00322139 0.0036384 ]\n",
            " [0.00293465 0.00261106 0.00367315 ... 0.0030414  0.00283023 0.00238187]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MUEUXBSlAXg7",
        "colab_type": "code",
        "outputId": "5da39e69-7c72-490e-ecd5-f0833b3a1c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "#jakie klasy byly naczesciej(znajdowaly sie w pierwszej 15 najbardziej prawdopodobnych) wybierane\n",
        "def choose_best_predicted_classes():\n",
        "  all_row_best_pred = []\n",
        "  plt_data = [0 for svm_class in svm_labels]\n",
        "  for prob_prediction in proba_predictions:\n",
        "    pair_prob_prediction = [(idx, element) for idx, element in enumerate(prob_prediction)]\n",
        "    sorted_prob_prediction = list(prob_prediction)\n",
        "    pair_prob_prediction_sorted = sorted(pair_prob_prediction, key=lambda ele: ele[1])\n",
        "    best_pred = pair_prob_prediction_sorted[-15:]\n",
        "    all_row_best_pred.append(best_pred)\n",
        "    for pred_class in best_pred:\n",
        "      plt_data[pred_class[0]] += 1\n",
        "  return all_row_best_pred,plt_data \n",
        "\n",
        "all_row_best_pred, plt_data = choose_best_predicted_classes()  \n",
        "\n",
        "\n",
        "# print (plt_data)\n",
        "bar_width = 1\n",
        "# widths = [10  for i in range(len(svm_labels))]   \n",
        "y_pos = range(len(svm_labels))\n",
        "performance = plt_data\n",
        "l_y_pos = list(y_pos)\n",
        "l_y_pos = l_y_pos[:250]\n",
        "np_y_pos = np.array(l_y_pos)\n",
        "plt.bar(np_y_pos + bar_width, performance[:250], align='center', alpha=0.5)\n",
        "plt.xticks(np_y_pos + bar_width / 2)\n",
        "plt.ylabel('liczba wybran klasy')\n",
        "plt.xlabel('numer klasy')\n",
        "plt.title('rozklad wybierania klas jako sfailowane')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQkYwxyIiIiGWOQExERydj/A4AgRSHnrME4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5c15f46588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iccc9VCbqaxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "8c206d20-6a3e-415f-c6a7-66d8e41f10a5"
      },
      "cell_type": "code",
      "source": [
        "def create_fake_pred(quantity_of_predictions, quantity_oftests_set_as_failed=15):\n",
        "  import random\n",
        "  stats =  [0 for i in range(542)]\n",
        "  random_matrix_pred = []\n",
        "  for row_no in range(quantity_of_predictions):\n",
        "      random_pred_list = [1 for i in range(542)]\n",
        "      random_indexes_list = []\n",
        "      while (len(random_indexes_list) <  15):\n",
        "          drawn_index= random.randint(0,230)\n",
        "          if random.randint(0,230) not in random_indexes_list:\n",
        "            random_indexes_list.append(drawn_index)\n",
        "          \n",
        "      for idx in random_indexes_list:\n",
        "        stats[idx] = stats[idx] + 1\n",
        "        \n",
        "      random_matrix_pred.append(random_indexes_list)\n",
        "      \n",
        "  random_matrix_pred = np.array(random_matrix_pred)\n",
        "  return random_matrix_pred, stats, \n",
        "\n",
        "stats = create_fake_pred(len(yTest))[1]\n",
        "y_pos = range(len(stats))\n",
        "performance = stats\n",
        "\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos)\n",
        "plt.ylabel('liczba wybran testu')\n",
        "plt.xlabel('numer testu')\n",
        "plt.title('rozklad wybierania testow jako sfailowane')\n",
        "plt.show()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nINQBADCJ/w9Y3CO6/a3NyAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5c1627ca20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UpriS5Jq9ByJ",
        "colab_type": "code",
        "outputId": "cb685f79-c39d-4b42-a3e1-93ca0d0bf4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#evaluation \n",
        "\n",
        "def read_predicted_tests_numbers(best_pred): \n",
        "  svm_pred_to_fail = []\n",
        "  test_counter = 0\n",
        "  for svm_class in best_pred:\n",
        "    for ele in class_mapper:\n",
        "      if svm_class[0] == ele[1]:\n",
        "        for idx,test in enumerate(ele[0]):\n",
        "          if test == 0:\n",
        "            svm_pred_to_fail.append(idx)\n",
        "            test_counter += 1\n",
        "            if test_counter > 15:\n",
        "              return svm_pred_to_fail\n",
        "  else:\n",
        "    return svm_pred_to_fail\n",
        "  \n",
        "def read_real_tests_numbers(idx, ref_yTest):\n",
        "  real_class = class_mapper[int(yTest[idx])]\n",
        "  for pair in class_mapper:\n",
        "    if pair[1] == ref_yTest[idx]:\n",
        "      real_vector =  list(pair[0])\n",
        "  real_failed_tests_numbers = [test_id for test_id, test  in enumerate(real_vector) if test == 0]\n",
        "  return real_failed_tests_numbers\n",
        "  \n",
        "  \n",
        "def new_evaluation(all_row_best_pred, yTest, is_fake_pred=False):  \n",
        "  all_performances = []\n",
        "\n",
        "  for idx, best_pred in enumerate(all_row_best_pred): \n",
        "    real_failed_tests_numbers = set(read_real_tests_numbers(idx, yTest))\n",
        "    if is_fake_pred == True:\n",
        "      predicted_tests_numbers = set(best_pred)\n",
        "    else:\n",
        "      predicted_tests_numbers = set(read_predicted_tests_numbers(best_pred))\n",
        "    diffrence = real_failed_tests_numbers - predicted_tests_numbers\n",
        "    try:\n",
        "      single_perfomance = (1 - (len(diffrence)/len(real_failed_tests_numbers)))\n",
        "    except ZeroDivisionError:\n",
        "      print(\"skip eveluation due to no failed test in class\")\n",
        "      continue\n",
        "    all_performances.append(single_perfomance)\n",
        "  return all_performances\n",
        "\n",
        "  \n",
        "all_performance = new_evaluation(all_row_best_pred, yTest) \n",
        "average_performance = sum(all_performance)/ len(all_performance)\n",
        "print(\"============================================================================================\")\n",
        "fake_pred = create_fake_pred(len(yTest))[0]\n",
        "fake_evaluation = new_evaluation(fake_pred, yTest,is_fake_pred=True)\n",
        "average_fake_pred = sum(fake_evaluation)/ len(fake_evaluation)\n",
        "\n",
        "print(average_performance)\n",
        "print(average_fake_pred)  \n",
        "  \n",
        "  \n",
        "  \n",
        "          \n",
        "      \n",
        "\n",
        "  "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================================================\n",
            "0.12073490813648294\n",
            "0.014435695538057744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bmd8oveCCLdd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e8Ez4ulnAZAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "494a2822-ca42-457d-d6c7-e91bd608bcc3"
      },
      "cell_type": "code",
      "source": [
        "def svm_function(gamma_parameter):\n",
        "  global xTrain, yTrain, xTest, yTest, class_mapper\n",
        "  clf = svm.SVC(gamma=gamma_parameter,probability=True)#gamma 0.0001\n",
        "  clf.fit(xTrain, yTrain)\n",
        "\n",
        "  proba_predictions = clf.predict_proba(xTest)\n",
        "  \n",
        "  \n",
        "  def choose_best_predicted_classes():\n",
        "    all_row_best_pred = []\n",
        "    plt_data = [0 for svm_class in svm_labels]\n",
        "    for prob_prediction in proba_predictions:\n",
        "      pair_prob_prediction = [(idx, element) for idx, element in enumerate(prob_prediction)]\n",
        "      sorted_prob_prediction = list(prob_prediction)\n",
        "      pair_prob_prediction_sorted = sorted(pair_prob_prediction, key=lambda ele: ele[1])\n",
        "      best_pred = pair_prob_prediction_sorted[-15:]\n",
        "      all_row_best_pred.append(best_pred)\n",
        "      for pred_class in best_pred:\n",
        "        plt_data[pred_class[0]] += 1\n",
        "    return all_row_best_pred,plt_data \n",
        "  \n",
        "  all_row_best_pred, plt_data = choose_best_predicted_classes()\n",
        "  \n",
        "  def read_predicted_tests_numbers(best_pred): \n",
        "    svm_pred_to_fail = []\n",
        "    test_counter = 0\n",
        "    for svm_class in best_pred:\n",
        "      for ele in class_mapper:\n",
        "        if svm_class[0] == ele[1]:\n",
        "          for idx,test in enumerate(ele[0]):\n",
        "            if test == 0:\n",
        "              svm_pred_to_fail.append(idx)\n",
        "              test_counter += 1\n",
        "              if test_counter > 15:\n",
        "                return svm_pred_to_fail\n",
        "    else:\n",
        "      return svm_pred_to_fail\n",
        "  \n",
        "  def read_real_tests_numbers(idx, ref_yTest):\n",
        "    real_class = class_mapper[int(yTest[idx])]\n",
        "    for pair in class_mapper:\n",
        "      if pair[1] == ref_yTest[idx]:\n",
        "        real_vector =  list(pair[0])\n",
        "    real_failed_tests_numbers = [test_id for test_id, test  in enumerate(real_vector) if test == 0]\n",
        "    return real_failed_tests_numbers\n",
        "\n",
        "\n",
        "  def new_evaluation(all_row_best_pred, yTest, is_fake_pred=False):  \n",
        "    all_performances = []\n",
        "    for idx, best_pred in enumerate(all_row_best_pred): \n",
        "      real_failed_tests_numbers = set(read_real_tests_numbers(idx, yTest))\n",
        "      if is_fake_pred == True:\n",
        "        predicted_tests_numbers = set(best_pred)\n",
        "      else:\n",
        "        predicted_tests_numbers = set(read_predicted_tests_numbers(best_pred))\n",
        "      diffrence = real_failed_tests_numbers - predicted_tests_numbers\n",
        "      try:\n",
        "        single_perfomance = (1 - (len(diffrence)/len(real_failed_tests_numbers)))\n",
        "      except ZeroDivisionError:\n",
        "        print(\"skip eveluation due to no failed test in class\")\n",
        "        continue\n",
        "      all_performances.append(single_perfomance)\n",
        "    return all_performances\n",
        "\n",
        "  \n",
        "  \n",
        "  all_performance = new_evaluation(all_row_best_pred, yTest) \n",
        "  average_performance = sum(all_performance)/ len(all_performance)\n",
        "  return average_performance\n",
        "\n",
        "\n",
        "svm_function(0.01)  \n",
        "  \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12598425196850394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "kdYFkbQyLR90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQif5IkFLMDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotData = []\n",
        "iterationCounter = 0\n",
        "recurencyCounter = 0\n",
        "bestResult = None\n",
        "\n",
        "\n",
        "def returnStepList(minValue, maxValue, nrSteps):\n",
        "    step = math.fabs(maxValue - minValue)/nrSteps\n",
        "    actualMin = min([minValue, maxValue])\n",
        "    actualMax = max([minValue, maxValue])\n",
        "    return [actualMin + step*nr for nr in range(nrSteps + 1)]\n",
        "  \n",
        "  \n",
        "def resetIterators():\n",
        "  global plotData\n",
        "  global iterationCounter\n",
        "  if plotData:\n",
        "    plotData = []\n",
        "  if iterationCounter:\n",
        "    iterationCounter = 0\n",
        "    \n",
        "\n",
        "def create_plot_optimizer(x_data, y_data=0, xLabel = 'X', yLabel = 'Y'):\n",
        "    import matplotlib.pyplot as plt\n",
        "    if y_data == 0:  \n",
        "        unzip = list(zip(*x_data))\n",
        "        x_data, y_data = unzip[0],unzip[1]\n",
        "    plt.plot(x_data, y_data)\n",
        "    plt.xlabel(xLabel)\n",
        "    plt.ylabel(yLabel)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def optimize(func, steps, minMax1, minMax2=False, split = 4, reduceSplit = False):\n",
        "    global iterationCounter\n",
        "    global recurencyCounter\n",
        "    global bestResult\n",
        "    singleParam = False\n",
        "    bestPair = [None, None]\n",
        "    resultList = []\n",
        "    parametersList=[]\n",
        "            \n",
        "            \n",
        "    if reduceSplit is False:\n",
        "      newSplit = split\n",
        "    else:\n",
        "      if split > 2:\n",
        "        newSplit = split - 1\n",
        "      else:\n",
        "        newSplit = 2\n",
        "    if split > 10:\n",
        "      raise ValueError(\"Too big value of 'split' parameter! This would highly increase number of iterations\")\n",
        "    \n",
        "    if minMax2 is False:\n",
        "      singleParam = True\n",
        "       \n",
        "    recurencyCounter += 1\n",
        "#     try:\n",
        "    if True:\n",
        "        if isinstance(minMax1, list):\n",
        "            \n",
        "            stepList1 = returnStepList(minMax1[0], minMax1[1], split)\n",
        "            if singleParam:\n",
        "              stepList2 = []\n",
        "              stepList2.append(1.0)\n",
        "            else:\n",
        "              stepList2 = returnStepList(minMax2[0], minMax2[1], split)\n",
        "            \n",
        "            i1 = 0\n",
        "            i2 = 0\n",
        "\n",
        "            \n",
        "            \n",
        "            for el1 in stepList1:\n",
        "                i2 = 0\n",
        "                for el2 in stepList2:\n",
        "                    iterationCounter += 1\n",
        "                    \n",
        "                    #----function----\n",
        "                    \n",
        "                    if singleParam:\n",
        "                      evaluation = func(el1)\n",
        "                    else:\n",
        "                      evaluation = func(el1, el2)\n",
        "\n",
        "                    #----function----\n",
        "                    \n",
        "                    \n",
        "                    \n",
        "                    if len(resultList) > 0:\n",
        "                        \n",
        "                        #----condition----\n",
        "                        if evaluation >= max(resultList):\n",
        "                            bestPair[0] = i1\n",
        "                            bestPair[1] = i2\n",
        "                        \n",
        "                        #----condition----\n",
        "                    else:\n",
        "                      if singleParam:\n",
        "                        bestPair[0] = i1\n",
        "                      else:\n",
        "                        bestPair[0] = i1\n",
        "                        bestPair[1] = i2\n",
        "                    \n",
        "                    plotData.append([evaluation, iterationCounter])\n",
        "\n",
        "                    resultList.append(evaluation)\n",
        "                    if singleParam:\n",
        "                      parametersList.append([el1])\n",
        "                    else:\n",
        "                      parametersList.append([el1, el2])\n",
        "\n",
        "                    i2 += 1\n",
        "                i1 += 1\n",
        "\n",
        "            #------------------------------------------------\n",
        "            \n",
        "            \n",
        "            if bestPair[0] == stepList1.index(stepList1[0]):\n",
        "                minMax1[0] = stepList1[bestPair[0]]/2\n",
        "                minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "#                 print(\"best values of PARAM_1 are close to MIN value\")\n",
        "                \n",
        "            elif bestPair[0] == stepList1.index(stepList1[-1]):\n",
        "                minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "                minMax1[1] = stepList1[bestPair[0]]*2\n",
        "#                 print(\"best values of PARAM_1 are close to MAX value\")\n",
        "\n",
        "                \n",
        "            else:\n",
        "                minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "                minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "            \n",
        "            #------------------------------------------------\n",
        "            if not singleParam:\n",
        "              if bestPair[1] == stepList2.index(stepList2[0]):\n",
        "                  minMax2[0] = stepList1[bestPair[1]]/2\n",
        "                  minMax2[1] = stepList1[bestPair[1] + 1]\n",
        "  #                 print(\"best values of PARAM_2 are close to MIN value\")\n",
        "\n",
        "              elif bestPair[1] == stepList2.index(stepList2[-1]):\n",
        "                  minMax2[0] = stepList1[bestPair[1] - 1]\n",
        "                  minMax2[1] = stepList1[bestPair[1]]*2\n",
        "  #                 print(\"best values of PARAM_2 are close to MAX value\")\n",
        "\n",
        "\n",
        "              else:\n",
        "                  minMax2[0] = stepList2[bestPair[1] - 1]\n",
        "                  minMax2[1] = stepList2[bestPair[1] + 1]\n",
        "\n",
        "            #------------------------------------------------\n",
        "            \n",
        "            \n",
        "            result = min(resultList)\n",
        "            param1 = parametersList[resultList.index(max(resultList))][0]\n",
        "            if not singleParam:\n",
        "              param2 = parametersList[resultList.index(max(resultList))][1]\n",
        "            if steps > 0:\n",
        "              if singleParam:\n",
        "                optimize(func, steps - 1, [minMax1[0], minMax1[1]], minMax2 = False, split = newSplit)\n",
        "              else:\n",
        "                optimize(func, steps - 1, [minMax1[0], minMax1[1]], [minMax2[0], minMax2[1]], newSplit)\n",
        "\n",
        "            else:\n",
        "              if singleParam:\n",
        "                print('--------ACHIEVED RESULTS--------')\n",
        "                print(\"{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',result,'PARAMETER 1: ', param1))\n",
        "                return [result, param1]\n",
        "              else:\n",
        "                print('--------ACHIEVED RESULTS--------')\n",
        "                print(\"{:<20}{}\\n{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',result,'PARAMETER 1: ', param1,'PARAMETER 2: ', param2))\n",
        "                return [result, param1, param2]\n",
        "            \n",
        "            \n",
        "\n",
        "        else:\n",
        "            print(\"enter correct value!\")\n",
        "#     except:\n",
        "#         print(\"---ERROR---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-IHOmht6rjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def exampleFunction(x, y=10):\n",
        "  return ((-20)* math.exp((((0.5*(x**2 + y**2))**0.5)*(-0.2))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtmzanFFnBwa",
        "colab_type": "code",
        "outputId": "fda53174-9a86-42b3-eb77-c60a68ad12c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "cell_type": "code",
      "source": [
        "#-------------------------------\n",
        "# steps       -->  number of iterations of recurency\n",
        "# spit        -->  number of parts in which function will split values of parameters\n",
        "#                  higher value -> better accuracy & longer calculation time\n",
        "#                  (Values range 2 -- 10)\n",
        "# reduceSplit -->  If True: with every repetition of recurency will reduce split by one\n",
        "\n",
        "\n",
        "resetIterators()\n",
        "optimize(svm_function, 4 , [0.0001,0.1], minMax2=False, split = 4, reduceSplit = True)\n",
        "xData = [num[1] for num in plotData]\n",
        "yData = [num[0] for num in plotData]\n",
        "\n",
        "create_plot_optimizer(xData, yData, 'Iterations', 'Result')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-8659e7731c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresetIterators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminMax2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceSplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mxData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0myData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-b14836e42212>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msingleParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                       \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                       \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-2c87cc693910>\u001b[0m in \u001b[0;36msvm_function\u001b[0;34m(gamma_parameter)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mglobal\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#gamma 0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mproba_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}