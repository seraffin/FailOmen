{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNOptimizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Wojtek/NNOptimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wha_2pSH9bO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#PREPARATIONS:"
      ]
    },
    {
      "metadata": {
        "id": "xK5iXVaJFZHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "# import keras\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSJbj3Ku9aco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9852c38a-202c-4df8-f6e8-cab8e4f65a0d"
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6LtbT258FTO",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "644b824e-90da-4586-8761-2f248c16356f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e8f64f59-3c27-4368-955e-3d221102b7d8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e8f64f59-3c27-4368-955e-3d221102b7d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving convertMinidataToML.csv to convertMinidataToML.csv\n",
            "User uploaded file \"convertMinidataToML.csv\" with length 1154382 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W5lgP4LSRhxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**UTILITIES:**"
      ]
    },
    {
      "metadata": {
        "id": "cHHl7dgH9HUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Optimizer:"
      ]
    },
    {
      "metadata": {
        "id": "sQif5IkFLMDE",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def optimizer(func, steps, minMax1, minMax2=False, split = 4, reduceSplit = False, searchMaximum = True):\n",
        "  \"\"\"\n",
        "  -------------------------------\n",
        "  Function can take 1 or 2 parameters to optimization.\n",
        "  Default: 2 parameters (you need to set values for minMax1 and minMax2)\n",
        "           For 1 parameter optimization set argument: \"minMax2 = False\"\n",
        "\n",
        "  -------------------------------\n",
        "  func        -->  enter your function there\n",
        "                   IMPORTANT:\n",
        "                   * if function has 1 parameter:  minMax1 = [min, max],   minMax2 = False\n",
        "                   * if function has 2 parameters: minMax1 = [min1, max1], minMax2 = [min2, max2]\n",
        "                   \n",
        "  steps       -->  number of iterations of recurency\n",
        "  \n",
        "  minMax1/2   -->  list of min and max value of parameters to begin with (ex. [min, max])\n",
        "  \n",
        "  split        -->  number of parts in which function will split values of parameters\n",
        "                   higher value -> better accuracy & longer calculation time\n",
        "                   (Values range 2 -- 10)\n",
        "                   \n",
        "  reduceSplit -->  If True: with every repetition of recurency will reduce split by one\n",
        "  \n",
        "  -------------------------------\n",
        "  \"\"\"\n",
        "  import matplotlib.pyplot as plt\n",
        "  import math\n",
        "  \n",
        "  \n",
        "  plotData = []\n",
        "  iterationCounter = 0\n",
        "  iterationsLeft = steps\n",
        "  recurencyCounter = 0\n",
        "  bestResult = None\n",
        "  print(iterationsLeft)\n",
        "  \n",
        "  #--------------------\n",
        "\n",
        "  def returnStepList(minValue, maxValue, nrSteps):\n",
        "      step = math.fabs(maxValue - minValue)/nrSteps\n",
        "      actualMin = min([minValue, maxValue])\n",
        "      actualMax = max([minValue, maxValue])\n",
        "      return [actualMin + step*nr for nr in range(nrSteps + 1)]\n",
        "\n",
        "  def resetIterators():\n",
        "    global plotData\n",
        "    global iterationCounter\n",
        "    global recurencyCounter\n",
        "    plotData = []\n",
        "    iterationCounter = 0\n",
        "    recurencyCounter = 0\n",
        "\n",
        "\n",
        "  def create_plot_optimizer(x_data, y_data=0, xLabel = 'X', yLabel = 'Y'):\n",
        "      import matplotlib.pyplot as plt\n",
        "      if y_data == 0:  \n",
        "          unzip = list(zip(*x_data))\n",
        "          x_data, y_data = unzip[0],unzip[1]\n",
        "      plt.plot(x_data, y_data)\n",
        "      plt.xlabel(xLabel)\n",
        "      plt.ylabel(yLabel)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def optimize(func, steps, minMax1, minMax2 = False, split = 4, reduceSplit = False, \n",
        "               searchMaximum = True, iLeft = None):\n",
        "      \n",
        "      global resetIterators\n",
        "      global iterationCounter\n",
        "      global iterationsLeft\n",
        "      global recurencyCounter\n",
        "      global bestResult\n",
        "      \n",
        "      localICounter = 0\n",
        "      iL = iLeft\n",
        "      sMax = searchMaximum\n",
        "      singleParam = False\n",
        "      bestPair = [None, None]\n",
        "      resultList = []\n",
        "      parametersList=[]\n",
        "\n",
        "      if reduceSplit is False:\n",
        "        newSplit = split\n",
        "      else:\n",
        "        if split > 2:\n",
        "          newSplit = split - 1\n",
        "        else:\n",
        "          newSplit = 2\n",
        "      if split > 10:\n",
        "        raise ValueError(\"Too big value of 'split' parameter! This would highly increase number of iterations\")\n",
        "      if minMax2 is False:\n",
        "        singleParam = True\n",
        "\n",
        "      recurencyCounter += 1\n",
        "\n",
        "      if isinstance(minMax1, list) and (isinstance(minMax2, list) or singleParam) :\n",
        "\n",
        "          stepList1 = returnStepList(minMax1[0], minMax1[1], split)\n",
        "          if singleParam:\n",
        "            stepList2 = [1]\n",
        "          else:\n",
        "            stepList2 = returnStepList(minMax2[0], minMax2[1], split)\n",
        "          \n",
        "          nrIterations = len(stepList1)*len(stepList2)\n",
        "          i1 = 0\n",
        "          i2 = 0\n",
        "\n",
        "\n",
        "\n",
        "          for el1 in stepList1:\n",
        "              i2 = 0\n",
        "              for el2 in stepList2:\n",
        "                  iterationCounter += 1\n",
        "                  localICounter += 1\n",
        "                  print(\"---Iteration: {0}/{1} ----Recurency: {2}/{3}\".format(localICounter, \n",
        "                                                              nrIterations,\n",
        "                                                              recurencyCounter,\n",
        "                                                              iL))\n",
        "\n",
        "                  #----function----\n",
        "                  if singleParam:\n",
        "                    evaluation = func(el1)\n",
        "                  else:\n",
        "                    evaluation = func(el1, el2)\n",
        "                  #----function----\n",
        "\n",
        "                  if len(resultList) > 0:\n",
        "                      #----condition----\n",
        "                      if sMax:\n",
        "                        if evaluation >= max(resultList):\n",
        "                            bestPair[0] = i1\n",
        "                            bestPair[1] = i2\n",
        "                      else:\n",
        "                        if evaluation <= min(resultList):\n",
        "                            bestPair[0] = i1\n",
        "                            bestPair[1] = i2\n",
        "\n",
        "                      #----condition----\n",
        "\n",
        "                  else:\n",
        "                    if singleParam:\n",
        "                      bestPair[0] = i1\n",
        "                    else:\n",
        "                      bestPair[0] = i1\n",
        "                      bestPair[1] = i2\n",
        "\n",
        "                  plotData.append([evaluation, iterationCounter])\n",
        "\n",
        "                  resultList.append(evaluation)\n",
        "                  if singleParam:\n",
        "                    parametersList.append([el1])\n",
        "                  else:\n",
        "                    parametersList.append([el1, el2])\n",
        "\n",
        "                  i2 += 1\n",
        "              i1 += 1\n",
        "\n",
        "          #------------------------------------------------\n",
        "\n",
        "\n",
        "          if bestPair[0] == stepList1.index(stepList1[0]):\n",
        "              minMax1[0] = stepList1[bestPair[0]]/2\n",
        "              minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "  #                 print(\"best values of PARAM_1 are close to MIN value\")\n",
        "\n",
        "          elif bestPair[0] == stepList1.index(stepList1[-1]):\n",
        "              minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "              minMax1[1] = stepList1[bestPair[0]]*2\n",
        "  #                 print(\"best values of PARAM_1 are close to MAX value\")\n",
        "\n",
        "\n",
        "          else:\n",
        "              minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "              minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "\n",
        "          #------------------------------------------------\n",
        "          if not singleParam:\n",
        "            if bestPair[1] == stepList2.index(stepList2[0]):\n",
        "                minMax2[0] = stepList1[bestPair[1]]/2\n",
        "                minMax2[1] = stepList1[bestPair[1] + 1]\n",
        "  #                 print(\"best values of PARAM_2 are close to MIN value\")\n",
        "\n",
        "            elif bestPair[1] == stepList2.index(stepList2[-1]):\n",
        "                minMax2[0] = stepList1[bestPair[1] - 1]\n",
        "                minMax2[1] = stepList1[bestPair[1]]*2\n",
        "  #                 print(\"best values of PARAM_2 are close to MAX value\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                minMax2[0] = stepList2[bestPair[1] - 1]\n",
        "                minMax2[1] = stepList2[bestPair[1] + 1]\n",
        "\n",
        "          #------------------------------------------------\n",
        "          if sMax:\n",
        "            result = max(resultList)\n",
        "            param1 = parametersList[resultList.index(max(resultList))][0]\n",
        "            if not singleParam:\n",
        "              param2 = parametersList[resultList.index(max(resultList))][1]\n",
        "          else:\n",
        "            result = min(resultList)\n",
        "            param1 = parametersList[resultList.index(min(resultList))][0]\n",
        "            if not singleParam:\n",
        "              param2 = parametersList[resultList.index(min(resultList))][1]\n",
        "                    \n",
        "          if steps > 0:\n",
        "            if singleParam:\n",
        "              print(\"---------------------------------------------------------\\n\")\n",
        "              optimize(func,\n",
        "                       steps - 1,\n",
        "                       [minMax1[0],minMax1[1]],\n",
        "                       minMax2 = False,\n",
        "                       split = newSplit,\n",
        "                       reduceSplit=reduceSplit,\n",
        "                       searchMaximum = sMax,\n",
        "                       iLeft = iL )\n",
        "            else:\n",
        "              print(\"---------------------------------------------------------\\n\")\n",
        "              optimize(func,\n",
        "                       steps - 1,\n",
        "                       [minMax1[0], minMax1[1]],\n",
        "                       minMax2=[minMax2[0], minMax2[1]],\n",
        "                       split = newSplit,\n",
        "                       reduceSplit=reduceSplit,\n",
        "                       searchMaximum = sMax,\n",
        "                       iLeft = iL)\n",
        "            \n",
        "          else:\n",
        "            if singleParam:\n",
        "              print('\\n------------------ACHIEVED RESULTS------------------\\n')\n",
        "              print(\"{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',\n",
        "                                                  result,\n",
        "                                                  'PARAMETER 1: ',\n",
        "                                                  param1))\n",
        "              return [result, param1]\n",
        "            else:\n",
        "              print('\\n------------------ACHIEVED RESULTS------------------\\n')\n",
        "              print(\"{:<20}{}\\n{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',\n",
        "                                                            result,\n",
        "                                                            'PARAMETER 1: ',\n",
        "                                                            param1,\n",
        "                                                            'PARAMETER 2: ',\n",
        "                                                            param2))\n",
        "              return [result, param1, param2]\n",
        "\n",
        "      else:\n",
        "          print(\"enter correct value!\")\n",
        "         \n",
        "  resetIterators()\n",
        "  result = optimize(func,\n",
        "                    steps,\n",
        "                    minMax1,\n",
        "                    minMax2,\n",
        "                    split,\n",
        "                    reduceSplit,\n",
        "                    searchMaximum = searchMaximum,\n",
        "                    iLeft = steps+1)\n",
        "  xData = [num[1] for num in plotData]\n",
        "  yData = [num[0] for num in plotData]\n",
        "  create_plot_optimizer(xData, yData, 'Iterations', 'Result')\n",
        "  return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DP1M6yYZ_H-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Example:"
      ]
    },
    {
      "metadata": {
        "id": "N7vEBvI6aWTt",
        "colab_type": "code",
        "outputId": "ab5f6517-5e5b-48f5-fcad-68b8a3b3f324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2163
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def exampleFunction(x, y = 5):\n",
        "  return ((-20)* math.exp((((0.5*(x**2 + y**2))**0.5)*(-0.2))))\n",
        "\n",
        "\n",
        "optimizer(exampleFunction, 12 , [-10,10], minMax2=False,  split = 10, reduceSplit = True, searchMaximum = True)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "---Iteration: 1/11 ----Recurency: 1/13\n",
            "---Iteration: 2/11 ----Recurency: 1/13\n",
            "---Iteration: 3/11 ----Recurency: 1/13\n",
            "---Iteration: 4/11 ----Recurency: 1/13\n",
            "---Iteration: 5/11 ----Recurency: 1/13\n",
            "---Iteration: 6/11 ----Recurency: 1/13\n",
            "---Iteration: 7/11 ----Recurency: 1/13\n",
            "---Iteration: 8/11 ----Recurency: 1/13\n",
            "---Iteration: 9/11 ----Recurency: 1/13\n",
            "---Iteration: 10/11 ----Recurency: 1/13\n",
            "---Iteration: 11/11 ----Recurency: 1/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/10 ----Recurency: 2/13\n",
            "---Iteration: 2/10 ----Recurency: 2/13\n",
            "---Iteration: 3/10 ----Recurency: 2/13\n",
            "---Iteration: 4/10 ----Recurency: 2/13\n",
            "---Iteration: 5/10 ----Recurency: 2/13\n",
            "---Iteration: 6/10 ----Recurency: 2/13\n",
            "---Iteration: 7/10 ----Recurency: 2/13\n",
            "---Iteration: 8/10 ----Recurency: 2/13\n",
            "---Iteration: 9/10 ----Recurency: 2/13\n",
            "---Iteration: 10/10 ----Recurency: 2/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/9 ----Recurency: 3/13\n",
            "---Iteration: 2/9 ----Recurency: 3/13\n",
            "---Iteration: 3/9 ----Recurency: 3/13\n",
            "---Iteration: 4/9 ----Recurency: 3/13\n",
            "---Iteration: 5/9 ----Recurency: 3/13\n",
            "---Iteration: 6/9 ----Recurency: 3/13\n",
            "---Iteration: 7/9 ----Recurency: 3/13\n",
            "---Iteration: 8/9 ----Recurency: 3/13\n",
            "---Iteration: 9/9 ----Recurency: 3/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/8 ----Recurency: 4/13\n",
            "---Iteration: 2/8 ----Recurency: 4/13\n",
            "---Iteration: 3/8 ----Recurency: 4/13\n",
            "---Iteration: 4/8 ----Recurency: 4/13\n",
            "---Iteration: 5/8 ----Recurency: 4/13\n",
            "---Iteration: 6/8 ----Recurency: 4/13\n",
            "---Iteration: 7/8 ----Recurency: 4/13\n",
            "---Iteration: 8/8 ----Recurency: 4/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/7 ----Recurency: 5/13\n",
            "---Iteration: 2/7 ----Recurency: 5/13\n",
            "---Iteration: 3/7 ----Recurency: 5/13\n",
            "---Iteration: 4/7 ----Recurency: 5/13\n",
            "---Iteration: 5/7 ----Recurency: 5/13\n",
            "---Iteration: 6/7 ----Recurency: 5/13\n",
            "---Iteration: 7/7 ----Recurency: 5/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/6 ----Recurency: 6/13\n",
            "---Iteration: 2/6 ----Recurency: 6/13\n",
            "---Iteration: 3/6 ----Recurency: 6/13\n",
            "---Iteration: 4/6 ----Recurency: 6/13\n",
            "---Iteration: 5/6 ----Recurency: 6/13\n",
            "---Iteration: 6/6 ----Recurency: 6/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/5 ----Recurency: 7/13\n",
            "---Iteration: 2/5 ----Recurency: 7/13\n",
            "---Iteration: 3/5 ----Recurency: 7/13\n",
            "---Iteration: 4/5 ----Recurency: 7/13\n",
            "---Iteration: 5/5 ----Recurency: 7/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/4 ----Recurency: 8/13\n",
            "---Iteration: 2/4 ----Recurency: 8/13\n",
            "---Iteration: 3/4 ----Recurency: 8/13\n",
            "---Iteration: 4/4 ----Recurency: 8/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 9/13\n",
            "---Iteration: 2/3 ----Recurency: 9/13\n",
            "---Iteration: 3/3 ----Recurency: 9/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 10/13\n",
            "---Iteration: 2/3 ----Recurency: 10/13\n",
            "---Iteration: 3/3 ----Recurency: 10/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 11/13\n",
            "---Iteration: 2/3 ----Recurency: 11/13\n",
            "---Iteration: 3/3 ----Recurency: 11/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 12/13\n",
            "---Iteration: 2/3 ----Recurency: 12/13\n",
            "---Iteration: 3/3 ----Recurency: 12/13\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 13/13\n",
            "---Iteration: 2/3 ----Recurency: 13/13\n",
            "---Iteration: 3/3 ----Recurency: 13/13\n",
            "\n",
            "------------------ACHIEVED RESULTS------------------\n",
            "\n",
            "RESULT:             -0.0\n",
            "PARAMETER 1:        13664.818386243387\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAALI8gBALAwghwAAAsjyAEAsLD/D38mILC558nLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fde166ca8d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PySAu2dE8rlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Other:**"
      ]
    },
    {
      "metadata": {
        "id": "zeL7SA0PLWsc",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def searchForFailed(yList):\n",
        "    changedRowList = []\n",
        "    for row in range (len(yList)):\n",
        "        if 0 in yList[row]:\n",
        "            changedRowList.append(row)\n",
        "    return changedRowList\n",
        "\n",
        "def returnFailedData(xList, yList, changedRowList):\n",
        "    xFailed = []\n",
        "    yFailed = []\n",
        "  \n",
        "    for row in changedRowList:\n",
        "        xFailed.append(xList[row])\n",
        "        yFailed.append(yList[row])\n",
        "    xFailed = np.array(xFailed)\n",
        "    yFailed = np.array(yFailed)\n",
        "    return xFailed, yFailed\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj27Oov0LYps",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def count_distribution(prediction):\n",
        "    #Distributions of argmins through all the predictions\n",
        "    i = 1\n",
        "    tab = [0] * 542\n",
        "    for a in prediction:\n",
        "        j = 0\n",
        "        for b in a:\n",
        "            if b < 1.0 : j = j + 1\n",
        "\n",
        "        #print (i, '. ', j, np.argmin(a))\n",
        "        tab[np.argmin(a)] += 1\n",
        "        i = i + 1\n",
        "\n",
        "    i = 0\n",
        "    distributed_array = []\n",
        "    for a in tab:\n",
        "        if a > 0 : \n",
        "            #print ('position', i, '\\targmin count', a)\n",
        "            distributed_array.append((i,a))\n",
        "        i += 1\n",
        "    create_plot(distributed_array)  \n",
        "    return distributed_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTmrDPbaLdDE",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def failsCount():\n",
        "    fala = 0\n",
        "    for i, a in enumerate(yTest):\n",
        "        j = 0\n",
        "        for k, b in enumerate(a):\n",
        "            if b < 1.0 : j += 1\n",
        "\n",
        "        if j > 0 : \n",
        "            print (i, '. ', j)\n",
        "        i = i + 1\n",
        "        fala += j\n",
        "    print (fala)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngL3fil-LeSt",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Evaluation function\n",
        "\n",
        "def evaluation(additionalPredictions, refYsupervisor, predictions):\n",
        "\n",
        "    lenght = len(refYsupervisor)\n",
        "\n",
        "    failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  \n",
        "    for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "        for j, b in enumerate(a):\n",
        "            if b == 0 : failPositions[i].append(j);\n",
        "\n",
        "    predictionsTemp = predictions.copy()\n",
        "    predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "    for i, a in enumerate(predictionsTemp):\n",
        "\n",
        "        if len(failPositions[i]) != 0:\n",
        "            for j in range(len(failPositions[i]) + additionalPredictions):\n",
        "                argmin = np.argmin(a)\n",
        "                predictionPositions[i].append(argmin)\n",
        "                predictionsTemp[i][argmin] = 1\n",
        "\n",
        "    predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "    for i, a in enumerate(failPositions):\n",
        "        count = 0\n",
        "        for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "            for c in predictionPositions[i]:\n",
        "  #      predictionHits[i].append(predictions[i][c].copy())\n",
        "  #      print(predictions[i][c])\n",
        "  #      print(predictions[i][c])\n",
        "  #      print (b, c)\n",
        "                if c == b : count += 1\n",
        "\n",
        "        if len(failPositions) != 0:\n",
        "            predictionHits[i].insert(0,count)\n",
        "\n",
        "\n",
        "    failsCount = 0\n",
        "    hitsCount = 0\n",
        "    for i, a in enumerate(refYsupervisor):\n",
        "        j = 0\n",
        "\n",
        "        for k, b in enumerate(a):\n",
        "            if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "        failsCount += j\n",
        "        hitsCount += predictionHits[i][0]\n",
        "    \n",
        "    percFailsPredicted = hitsCount / failsCount * 100\n",
        "    print('Percentage of fails predicted', hitsCount / failsCount * 100, '%')\n",
        "    return percFailsPredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUqLiUzV82wE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**NEURAL NETWORK:**"
      ]
    },
    {
      "metadata": {
        "id": "G9WRpAqz9pmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data:"
      ]
    },
    {
      "metadata": {
        "id": "Slq936w_LgQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7f5f2b4a-7cbd-4148-e9b4-4fafb979e64f"
      },
      "cell_type": "code",
      "source": [
        "#Importing dataset\n",
        "dataset = pd.read_csv('convertMinidataToML.csv', index_col=False)\n",
        "\n",
        "#Check the first 5 rows of the dataset. \n",
        "dataset.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>24272</th>\n",
              "      <th>24273</th>\n",
              "      <th>24274</th>\n",
              "      <th>24275</th>\n",
              "      <th>24276</th>\n",
              "      <th>24277</th>\n",
              "      <th>24278</th>\n",
              "      <th>24279</th>\n",
              "      <th>24280</th>\n",
              "      <th>24281</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  24281 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1  2  3  4  5  6  7  8  9  10  ...    24272  24273  24274  24275  24276  \\\n",
              "0  1  1  1  1  1  1  1  1  1   1  ...        1      1      1      1      1   \n",
              "1  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "2  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "3  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "4  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "\n",
              "   24277  24278  24279  24280  24281  \n",
              "0      1      1      1      1      1  \n",
              "1      1      1      1      1      1  \n",
              "2      1      1      1      1      1  \n",
              "3      1      1      1      1      1  \n",
              "4      1      1      1      1      1  \n",
              "\n",
              "[5 rows x 24281 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "2TS6_yWrL2Fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, 0:23739].values\n",
        "y = dataset.iloc[:, 23739:24281].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnPHXWnQL4NV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TCLVHfK7L6dt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(xReduced, yReduced, test_size = 0.2, random_state=77)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGWxKK3899YH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model definition:"
      ]
    },
    {
      "metadata": {
        "id": "4ETzd-5lL8R8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.backend.tensorflow_backend import set_session  \n",
        "# config = tf.ConfigProto()  \n",
        "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
        "# sess = tf.Session(config=config)  \n",
        "# set_session(sess)  # set this TensorFlow session as the default session for Keras.\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# Adding the input layer and the output layer\n",
        "# model.add(Dense(units = 542, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "voRGZ2SLL9vw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bfd8f474-bd1f-4b68-a014-28439fe1e763"
      },
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        " \n",
        "# model.fit(xTrain, yTrain, batch_size = 10, epochs = 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6956 - acc: 0.5138\n",
            "Epoch 2/2\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.5138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8358e99630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "SNKBm1XlMARd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculateNetwork(x):\n",
        "    inputUnits = int(x)\n",
        "    firstLayerUnits = 1000\n",
        "    secondLayerUnits = 542\n",
        "    if not isinstance(inputUnits, (int)) or not isinstance(firstLayerUnits, (int)) or not isinstance(secondLayerUnits, (int)):\n",
        "        print(\"Enter correct input!\")\\\n",
        "\n",
        "    else:\n",
        "        config = tf.ConfigProto()  \n",
        "        config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
        "        sess = tf.Session(config=config)  \n",
        "        set_session(sess)\n",
        "        pBatchSize = 10\n",
        "        pEpochs = 1\n",
        "        pLearningRate = 0.01\n",
        "        pMomentum = 0.04\n",
        "        \n",
        "        \n",
        "        model = Sequential()\n",
        "\n",
        "        # Adding the input layer and the first hidden layer\n",
        "        model.add(Dense(inputUnits, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "        # Adding the second hidden layer\n",
        "        model.add(Dense(firstLayerUnits, activation = \"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "        # Adding the output layer\n",
        "        model.add(Dense(secondLayerUnits, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "  \n",
        "  \n",
        "        model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = pLearningRate, momentum = pMomentum), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        model.fit(xTrain, yTrain, batch_size = pBatchSize, epochs = pEpochs)\n",
        "  \n",
        "        predictions = model.predict(xReduced)\n",
        "        evaluationResult = evaluation(15, yReduced, predictions)\n",
        "        K.clear_session()\n",
        "        return evaluationResult\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ssKmBP8MGF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5317
        },
        "outputId": "f1da08e9-7f5c-401b-c5cc-53203d578840"
      },
      "cell_type": "code",
      "source": [
        "optimizer(calculateNetwork, 4 , [100,1000], minMax2=False,  split = 4, reduceSplit = True, searchMaximum = True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "---Iteration: 1/5 ----Recurency: 1/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.7315 - acc: 0.4696\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 2/5 ----Recurency: 1/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 286ms/step - loss: 0.7096 - acc: 0.5286\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 3/5 ----Recurency: 1/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7232 - acc: 0.5000\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 4/5 ----Recurency: 1/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 352ms/step - loss: 0.7137 - acc: 0.5161\n",
            "Percentage of fails predicted 6.25 %\n",
            "---Iteration: 5/5 ----Recurency: 1/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.7358 - acc: 0.4691\n",
            "Percentage of fails predicted 0.0 %\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/4 ----Recurency: 2/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.7027 - acc: 0.5254\n",
            "Percentage of fails predicted 6.25 %\n",
            "---Iteration: 2/4 ----Recurency: 2/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.7382 - acc: 0.4576\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 3/4 ----Recurency: 2/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.7232 - acc: 0.4659\n",
            "Percentage of fails predicted 12.5 %\n",
            "---Iteration: 4/4 ----Recurency: 2/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.7326 - acc: 0.4779\n",
            "Percentage of fails predicted 12.5 %\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 3/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 1s 344ms/step - loss: 0.7253 - acc: 0.4866\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 2/3 ----Recurency: 3/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 2s 419ms/step - loss: 0.7006 - acc: 0.5208\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 3/3 ----Recurency: 3/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.7125 - acc: 0.4991\n",
            "Percentage of fails predicted 6.25 %\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/3 ----Recurency: 4/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 2s 411ms/step - loss: 0.7176 - acc: 0.4940\n",
            "Percentage of fails predicted 12.5 %\n",
            "---Iteration: 2/3 ----Recurency: 4/5\n",
            "Epoch 1/1\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.7199 - acc: 0.5203\n",
            "Percentage of fails predicted 0.0 %\n",
            "---Iteration: 3/3 ----Recurency: 4/5\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [23739,4000] and type float\n\t [[{{node dense_104/kernel/Momentum/Initializer/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,4000] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0319ab102b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculateNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminMax2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceSplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchMaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-c8895263d82b>\u001b[0m in \u001b[0;36moptimizer\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit, searchMaximum)\u001b[0m\n\u001b[1;32m    254\u001b[0m                     \u001b[0mreduceSplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0msearchMaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchMaximum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     iLeft = steps+1)\n\u001b[0m\u001b[1;32m    257\u001b[0m   \u001b[0mxData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0myData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c8895263d82b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit, searchMaximum, iLeft)\u001b[0m\n\u001b[1;32m    213\u001b[0m                        \u001b[0mreduceSplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduceSplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                        \u001b[0msearchMaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msMax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                        iLeft = iL )\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c8895263d82b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit, searchMaximum, iLeft)\u001b[0m\n\u001b[1;32m    213\u001b[0m                        \u001b[0mreduceSplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduceSplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                        \u001b[0msearchMaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msMax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                        iLeft = iL )\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c8895263d82b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit, searchMaximum, iLeft)\u001b[0m\n\u001b[1;32m    213\u001b[0m                        \u001b[0mreduceSplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduceSplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                        \u001b[0msearchMaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msMax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                        iLeft = iL )\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c8895263d82b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(func, steps, minMax1, minMax2, split, reduceSplit, searchMaximum, iLeft)\u001b[0m\n\u001b[1;32m    120\u001b[0m                   \u001b[0;31m#----function----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                   \u001b[0;32mif\u001b[0m \u001b[0msingleParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-ac456bb25366>\u001b[0m in \u001b[0;36mcalculateNetwork\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxReduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [23739,4000] and type float\n\t [[node dense_104/kernel/Momentum/Initializer/zeros (defined at /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:709)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,4000] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'dense_104/kernel/Momentum/Initializer/zeros', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-0319ab102b50>\", line 1, in <module>\n    optimizer(calculateNetwork, 4 , [100,1000], minMax2=False,  split = 4, reduceSplit = True, searchMaximum = True)\n  File \"<ipython-input-8-c8895263d82b>\", line 256, in optimizer\n    iLeft = steps+1)\n  File \"<ipython-input-8-c8895263d82b>\", line 215, in optimize\n    iLeft = iL )\n  File \"<ipython-input-8-c8895263d82b>\", line 215, in optimize\n    iLeft = iL )\n  File \"<ipython-input-8-c8895263d82b>\", line 215, in optimize\n    iLeft = iL )\n  File \"<ipython-input-8-c8895263d82b>\", line 122, in optimize\n    evaluation = func(el1)\n  File \"<ipython-input-27-ac456bb25366>\", line 24, in calculateNetwork\n    model.fit(xTrain, yTrain, batch_size = pBatchSize, epochs = pEpochs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1010, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 509, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 709, in get_updates\n    grads, global_step=self.iterations)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/momentum.py\", line 77, in _create_slots\n    self._zeros_slot(v, \"momentum\", self._name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py\", line 101, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1563, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2979, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [23739,4000] and type float\n\t [[node dense_104/kernel/Momentum/Initializer/zeros (defined at /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:709)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,4000] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
          ]
        }
      ]
    }
  ]
}