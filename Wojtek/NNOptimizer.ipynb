{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNOptimizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Wojtek/NNOptimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wha_2pSH9bO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#PREPARATIONS:"
      ]
    },
    {
      "metadata": {
        "id": "xK5iXVaJFZHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "# import keras\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSJbj3Ku9aco",
        "colab_type": "code",
        "outputId": "02c86729-64cc-4985-870b-b13189f63409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6LtbT258FTO",
        "colab_type": "code",
        "outputId": "99352eeb-3e44-49bd-9413-0b4b4c0d96e0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf1cd707-c16a-4c16-9826-1b63d3767aef\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cf1cd707-c16a-4c16-9826-1b63d3767aef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataToML_full6.csv to dataToML_full6.csv\n",
            "User uploaded file \"dataToML_full6.csv\" with length 499100229 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W5lgP4LSRhxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**UTILITIES:**"
      ]
    },
    {
      "metadata": {
        "id": "cHHl7dgH9HUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Optimizer:"
      ]
    },
    {
      "metadata": {
        "id": "sQif5IkFLMDE",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "class optimizer:\n",
        "  \"\"\"\n",
        "  -------------------------------\n",
        "  Function can take 1 or 2 parameters to optimization.\n",
        "  Default: 2 parameters (you need to set values for minMax1 and minMax2)\n",
        "           For 1 parameter optimization set argument: \"minMax2 = False\"\n",
        "\n",
        "  -------------------------------\n",
        "  func        -->  enter your function there\n",
        "                   IMPORTANT:\n",
        "                   * if function has 1 parameter:  minMax1 = [min, max],   minMax2 = False\n",
        "                   * if function has 2 parameters: minMax1 = [min1, max1], minMax2 = [min2, max2]\n",
        "                   \n",
        "  steps       -->  number of iterations of recurency\n",
        "  \n",
        "  minMax1/2   -->  list of min and max value of parameters to begin with (ex. [min, max])\n",
        "  \n",
        "  split        -->  number of parts in which function will split values of parameters\n",
        "                   higher value -> better accuracy & longer calculation time\n",
        "                   (Values range 2 -- 10)\n",
        "                   \n",
        "  reduceSplit -->  If True: with every repetition of recurency will reduce split by one\n",
        "  \n",
        "  -------------------------------\n",
        "  \"\"\"\n",
        "  \n",
        "  import matplotlib.pyplot as plt\n",
        "  import math\n",
        "  \n",
        "  \n",
        "  \n",
        "  def __init__(self, func, steps, minMax1, minMax2=False, split = 4, reduceSplit = False, searchMaximum = True):\n",
        "    self.plotData = []\n",
        "    self.iterationCounter = 0\n",
        "    self.iterationsLeft = steps\n",
        "    self.recurencyCounter = 0\n",
        "    self.bestResults = []\n",
        "    \n",
        "    self.resetIterators()\n",
        "    self.optimize(func,\n",
        "                  steps,\n",
        "                  minMax1,\n",
        "                  minMax2,\n",
        "                  split,\n",
        "                  reduceSplit,\n",
        "                  searchMaximum = searchMaximum,\n",
        "                  iLeft = steps+1)\n",
        "    print(self.bestResults)\n",
        "    xData = [num[1] for num in self.plotData]\n",
        "    yData = [num[0] for num in self.plotData]\n",
        "    self.create_plot_optimizer(xData, yData, 'Iterations', 'Result')\n",
        "#     return self.bestResults\n",
        "  \n",
        " \n",
        "  #--------------------\n",
        "\n",
        "  def returnStepList(self, minValue, maxValue, nrSteps):\n",
        "      step = math.fabs(maxValue - minValue)/nrSteps\n",
        "      actualMin = min([minValue, maxValue])\n",
        "      actualMax = max([minValue, maxValue])\n",
        "      return [actualMin + step*nr for nr in range(nrSteps + 1)]\n",
        "\n",
        "  def resetIterators(self):\n",
        "    self.plotData = []\n",
        "    self.iterationCounter = 0\n",
        "    self.recurencyCounter = 0\n",
        "\n",
        "\n",
        "  def create_plot_optimizer(self, x_data, y_data=0, xLabel = 'X', yLabel = 'Y'):\n",
        "      import matplotlib.pyplot as plt\n",
        "\n",
        "      if y_data == 0:  \n",
        "          unzip = list(zip(*x_data))\n",
        "          x_data, y_data = unzip[0],unzip[1]\n",
        "      plt.plot(x_data, y_data)\n",
        "      plt.xlabel(xLabel)\n",
        "      plt.ylabel(yLabel)\n",
        "      plt.show()\n",
        "\n",
        "  def findBestSolution(self, searchMaximum):\n",
        "      best = [0]\n",
        "      for res in self.bestResults:\n",
        "        if searchMaximum:\n",
        "          if res[0] >= best[0]:\n",
        "            best = res\n",
        "        else:\n",
        "          if res[0] <= best[0]:\n",
        "            best = res\n",
        "      \n",
        "      \n",
        "      if len(self.bestResults[0]) == 2:\n",
        "        print('\\n------------------ACHIEVED RESULTS------------------\\n')\n",
        "        print(\"{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',\n",
        "                                            best[0],\n",
        "                                            'PARAMETER 1: ',\n",
        "                                            best[1]))\n",
        "#               return bestResult\n",
        "      elif len(self.bestResults[0]) == 3:\n",
        "        print('\\n------------------ACHIEVED RESULTS------------------\\n')\n",
        "        print(\"{:<20}{}\\n{:<20}{}\\n{:<20}{}\\n\".format('RESULT: ',\n",
        "                                                      best[0],\n",
        "                                                      'PARAMETER 1: ',\n",
        "                                                      best[1],\n",
        "                                                      'PARAMETER 2: ',\n",
        "                                                      best[2]))\n",
        "      else:\n",
        "        print(\"no optimization results record\")\n",
        "        \n",
        "        \n",
        "  def optimize(self, func, steps, minMax1, minMax2 = False, split = 4, reduceSplit = False, \n",
        "               searchMaximum = True, iLeft = None):\n",
        "      \n",
        "      bestResult = []\n",
        "      \n",
        "      localICounter = 0\n",
        "      iL = iLeft\n",
        "      sMax = searchMaximum\n",
        "      singleParam = False\n",
        "      bestPair = [None, None]\n",
        "      resultList = []\n",
        "      parametersList=[]\n",
        "\n",
        "      if reduceSplit is False:\n",
        "        newSplit = split\n",
        "      else:\n",
        "        if split > 2:\n",
        "          newSplit = split - 1\n",
        "        else:\n",
        "          newSplit = 2\n",
        "      if split > 10:\n",
        "        raise ValueError(\"Too big value of 'split' parameter! This would highly increase number of iterations\")\n",
        "      if minMax2 is False:\n",
        "        singleParam = True\n",
        "\n",
        "      self.recurencyCounter += 1\n",
        "\n",
        "      if isinstance(minMax1, list) and (isinstance(minMax2, list) or singleParam) :\n",
        "\n",
        "          stepList1 = self.returnStepList(minMax1[0], minMax1[1], split)\n",
        "          if singleParam:\n",
        "            stepList2 = [1]\n",
        "          else:\n",
        "            stepList2 = self.returnStepList(minMax2[0], minMax2[1], split)\n",
        "          \n",
        "          nrIterations = len(stepList1)*len(stepList2)\n",
        "          i1 = 0\n",
        "          i2 = 0\n",
        "\n",
        "\n",
        "\n",
        "          for el1 in stepList1:\n",
        "              i2 = 0\n",
        "              for el2 in stepList2:\n",
        "                  self.iterationCounter += 1\n",
        "                  localICounter += 1\n",
        "                  print(\"---Iteration: {0}/{1} ----Recurency: {2}/{3}\".format(localICounter, \n",
        "                                                              nrIterations,\n",
        "                                                              self.recurencyCounter,\n",
        "                                                              iL))\n",
        "\n",
        "                  #----function----\n",
        "                  if singleParam:\n",
        "                    evaluation = func(el1)\n",
        "                  else:\n",
        "                    evaluation = func(el1, el2)\n",
        "                  #----function----\n",
        "\n",
        "                  if len(resultList) > 0:\n",
        "                      #----condition----\n",
        "                      if sMax:\n",
        "                        if evaluation >= max(resultList):\n",
        "                            bestPair[0] = i1\n",
        "                            bestPair[1] = i2\n",
        "                      else:\n",
        "                        if evaluation <= min(resultList):\n",
        "                            bestPair[0] = i1\n",
        "                            bestPair[1] = i2\n",
        "\n",
        "                      #----condition----\n",
        "\n",
        "                  else:\n",
        "                    if singleParam:\n",
        "                      bestPair[0] = i1\n",
        "                    else:\n",
        "                      bestPair[0] = i1\n",
        "                      bestPair[1] = i2\n",
        "\n",
        "                  self.plotData.append([evaluation, self.iterationCounter])\n",
        "\n",
        "                  resultList.append(evaluation)\n",
        "                  if singleParam:\n",
        "                    parametersList.append([el1])\n",
        "                  else:\n",
        "                    parametersList.append([el1, el2])\n",
        "\n",
        "                  i2 += 1\n",
        "              i1 += 1\n",
        "\n",
        "          #------------------------------------------------\n",
        "\n",
        "\n",
        "          if bestPair[0] == stepList1.index(stepList1[0]):\n",
        "              minMax1[0] = stepList1[bestPair[0]]/2\n",
        "              minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "  #                 print(\"best values of PARAM_1 are close to MIN value\")\n",
        "\n",
        "          elif bestPair[0] == stepList1.index(stepList1[-1]):\n",
        "              minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "              minMax1[1] = stepList1[bestPair[0]]*2\n",
        "  #                 print(\"best values of PARAM_1 are close to MAX value\")\n",
        "\n",
        "\n",
        "          else:\n",
        "              minMax1[0] = stepList1[bestPair[0] - 1]\n",
        "              minMax1[1] = stepList1[bestPair[0] + 1]\n",
        "\n",
        "          #------------------------------------------------\n",
        "          if not singleParam:\n",
        "            if bestPair[1] == stepList2.index(stepList2[0]):\n",
        "                minMax2[0] = stepList1[bestPair[1]]/2\n",
        "                minMax2[1] = stepList1[bestPair[1] + 1]\n",
        "  #                 print(\"best values of PARAM_2 are close to MIN value\")\n",
        "\n",
        "            elif bestPair[1] == stepList2.index(stepList2[-1]):\n",
        "                minMax2[0] = stepList1[bestPair[1] - 1]\n",
        "                minMax2[1] = stepList1[bestPair[1]]*2\n",
        "  #                 print(\"best values of PARAM_2 are close to MAX value\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                minMax2[0] = stepList2[bestPair[1] - 1]\n",
        "                minMax2[1] = stepList2[bestPair[1] + 1]\n",
        "\n",
        "          #------------------------------------------------\n",
        "          if sMax:\n",
        "            result = max(resultList)\n",
        "            param1 = parametersList[resultList.index(max(resultList))][0]\n",
        "            if not singleParam:\n",
        "              param2 = parametersList[resultList.index(max(resultList))][1]\n",
        "          else:\n",
        "            result = min(resultList)\n",
        "            param1 = parametersList[resultList.index(min(resultList))][0]\n",
        "            if not singleParam:\n",
        "              param2 = parametersList[resultList.index(min(resultList))][1]\n",
        "          \n",
        "          if singleParam:\n",
        "            self.bestResults.append([result, param1])\n",
        "          else:\n",
        "            self.bestResults.append([result, param1, param2])\n",
        "\n",
        "          if steps > 0:\n",
        "            if singleParam:\n",
        "              print(\"---------------------------------------------------------\\n\")\n",
        "              self.optimize(func,\n",
        "                           steps - 1,\n",
        "                           [minMax1[0],minMax1[1]],\n",
        "                           minMax2 = False,\n",
        "                           split = newSplit,\n",
        "                           reduceSplit=reduceSplit,\n",
        "                           searchMaximum = sMax,\n",
        "                           iLeft = iL )\n",
        "            else:\n",
        "              print(\"---------------------------------------------------------\\n\")\n",
        "              self.optimize(func,\n",
        "                           steps - 1,\n",
        "                           [minMax1[0], minMax1[1]],\n",
        "                           minMax2=[minMax2[0], minMax2[1]],\n",
        "                           split = newSplit,\n",
        "                           reduceSplit=reduceSplit,\n",
        "                           searchMaximum = sMax,\n",
        "                           iLeft = iL)\n",
        "            \n",
        "          else:\n",
        "            self.findBestSolution(searchMaximum)\n",
        "\n",
        "      else:\n",
        "          print(\"enter correct value!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DP1M6yYZ_H-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Example:"
      ]
    },
    {
      "metadata": {
        "id": "N7vEBvI6aWTt",
        "colab_type": "code",
        "outputId": "21aedcf7-5898-407d-b5d1-811b8e68eb67",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3900
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def exampleFunction(x, y = 5):\n",
        "  return ((-20)* math.exp((((0.5*(x**2 + y**2))**0.5)*(-0.2))))\n",
        "\n",
        "\n",
        "r = optimizer(exampleFunction, 4 , [-10,10], minMax2=[-10, 10],  split = 7, reduceSplit = True, searchMaximum = False)\n",
        "print(r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Iteration: 1/64 ----Recurency: 1/5\n",
            "---Iteration: 2/64 ----Recurency: 1/5\n",
            "---Iteration: 3/64 ----Recurency: 1/5\n",
            "---Iteration: 4/64 ----Recurency: 1/5\n",
            "---Iteration: 5/64 ----Recurency: 1/5\n",
            "---Iteration: 6/64 ----Recurency: 1/5\n",
            "---Iteration: 7/64 ----Recurency: 1/5\n",
            "---Iteration: 8/64 ----Recurency: 1/5\n",
            "---Iteration: 9/64 ----Recurency: 1/5\n",
            "---Iteration: 10/64 ----Recurency: 1/5\n",
            "---Iteration: 11/64 ----Recurency: 1/5\n",
            "---Iteration: 12/64 ----Recurency: 1/5\n",
            "---Iteration: 13/64 ----Recurency: 1/5\n",
            "---Iteration: 14/64 ----Recurency: 1/5\n",
            "---Iteration: 15/64 ----Recurency: 1/5\n",
            "---Iteration: 16/64 ----Recurency: 1/5\n",
            "---Iteration: 17/64 ----Recurency: 1/5\n",
            "---Iteration: 18/64 ----Recurency: 1/5\n",
            "---Iteration: 19/64 ----Recurency: 1/5\n",
            "---Iteration: 20/64 ----Recurency: 1/5\n",
            "---Iteration: 21/64 ----Recurency: 1/5\n",
            "---Iteration: 22/64 ----Recurency: 1/5\n",
            "---Iteration: 23/64 ----Recurency: 1/5\n",
            "---Iteration: 24/64 ----Recurency: 1/5\n",
            "---Iteration: 25/64 ----Recurency: 1/5\n",
            "---Iteration: 26/64 ----Recurency: 1/5\n",
            "---Iteration: 27/64 ----Recurency: 1/5\n",
            "---Iteration: 28/64 ----Recurency: 1/5\n",
            "---Iteration: 29/64 ----Recurency: 1/5\n",
            "---Iteration: 30/64 ----Recurency: 1/5\n",
            "---Iteration: 31/64 ----Recurency: 1/5\n",
            "---Iteration: 32/64 ----Recurency: 1/5\n",
            "---Iteration: 33/64 ----Recurency: 1/5\n",
            "---Iteration: 34/64 ----Recurency: 1/5\n",
            "---Iteration: 35/64 ----Recurency: 1/5\n",
            "---Iteration: 36/64 ----Recurency: 1/5\n",
            "---Iteration: 37/64 ----Recurency: 1/5\n",
            "---Iteration: 38/64 ----Recurency: 1/5\n",
            "---Iteration: 39/64 ----Recurency: 1/5\n",
            "---Iteration: 40/64 ----Recurency: 1/5\n",
            "---Iteration: 41/64 ----Recurency: 1/5\n",
            "---Iteration: 42/64 ----Recurency: 1/5\n",
            "---Iteration: 43/64 ----Recurency: 1/5\n",
            "---Iteration: 44/64 ----Recurency: 1/5\n",
            "---Iteration: 45/64 ----Recurency: 1/5\n",
            "---Iteration: 46/64 ----Recurency: 1/5\n",
            "---Iteration: 47/64 ----Recurency: 1/5\n",
            "---Iteration: 48/64 ----Recurency: 1/5\n",
            "---Iteration: 49/64 ----Recurency: 1/5\n",
            "---Iteration: 50/64 ----Recurency: 1/5\n",
            "---Iteration: 51/64 ----Recurency: 1/5\n",
            "---Iteration: 52/64 ----Recurency: 1/5\n",
            "---Iteration: 53/64 ----Recurency: 1/5\n",
            "---Iteration: 54/64 ----Recurency: 1/5\n",
            "---Iteration: 55/64 ----Recurency: 1/5\n",
            "---Iteration: 56/64 ----Recurency: 1/5\n",
            "---Iteration: 57/64 ----Recurency: 1/5\n",
            "---Iteration: 58/64 ----Recurency: 1/5\n",
            "---Iteration: 59/64 ----Recurency: 1/5\n",
            "---Iteration: 60/64 ----Recurency: 1/5\n",
            "---Iteration: 61/64 ----Recurency: 1/5\n",
            "---Iteration: 62/64 ----Recurency: 1/5\n",
            "---Iteration: 63/64 ----Recurency: 1/5\n",
            "---Iteration: 64/64 ----Recurency: 1/5\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/49 ----Recurency: 2/5\n",
            "---Iteration: 2/49 ----Recurency: 2/5\n",
            "---Iteration: 3/49 ----Recurency: 2/5\n",
            "---Iteration: 4/49 ----Recurency: 2/5\n",
            "---Iteration: 5/49 ----Recurency: 2/5\n",
            "---Iteration: 6/49 ----Recurency: 2/5\n",
            "---Iteration: 7/49 ----Recurency: 2/5\n",
            "---Iteration: 8/49 ----Recurency: 2/5\n",
            "---Iteration: 9/49 ----Recurency: 2/5\n",
            "---Iteration: 10/49 ----Recurency: 2/5\n",
            "---Iteration: 11/49 ----Recurency: 2/5\n",
            "---Iteration: 12/49 ----Recurency: 2/5\n",
            "---Iteration: 13/49 ----Recurency: 2/5\n",
            "---Iteration: 14/49 ----Recurency: 2/5\n",
            "---Iteration: 15/49 ----Recurency: 2/5\n",
            "---Iteration: 16/49 ----Recurency: 2/5\n",
            "---Iteration: 17/49 ----Recurency: 2/5\n",
            "---Iteration: 18/49 ----Recurency: 2/5\n",
            "---Iteration: 19/49 ----Recurency: 2/5\n",
            "---Iteration: 20/49 ----Recurency: 2/5\n",
            "---Iteration: 21/49 ----Recurency: 2/5\n",
            "---Iteration: 22/49 ----Recurency: 2/5\n",
            "---Iteration: 23/49 ----Recurency: 2/5\n",
            "---Iteration: 24/49 ----Recurency: 2/5\n",
            "---Iteration: 25/49 ----Recurency: 2/5\n",
            "---Iteration: 26/49 ----Recurency: 2/5\n",
            "---Iteration: 27/49 ----Recurency: 2/5\n",
            "---Iteration: 28/49 ----Recurency: 2/5\n",
            "---Iteration: 29/49 ----Recurency: 2/5\n",
            "---Iteration: 30/49 ----Recurency: 2/5\n",
            "---Iteration: 31/49 ----Recurency: 2/5\n",
            "---Iteration: 32/49 ----Recurency: 2/5\n",
            "---Iteration: 33/49 ----Recurency: 2/5\n",
            "---Iteration: 34/49 ----Recurency: 2/5\n",
            "---Iteration: 35/49 ----Recurency: 2/5\n",
            "---Iteration: 36/49 ----Recurency: 2/5\n",
            "---Iteration: 37/49 ----Recurency: 2/5\n",
            "---Iteration: 38/49 ----Recurency: 2/5\n",
            "---Iteration: 39/49 ----Recurency: 2/5\n",
            "---Iteration: 40/49 ----Recurency: 2/5\n",
            "---Iteration: 41/49 ----Recurency: 2/5\n",
            "---Iteration: 42/49 ----Recurency: 2/5\n",
            "---Iteration: 43/49 ----Recurency: 2/5\n",
            "---Iteration: 44/49 ----Recurency: 2/5\n",
            "---Iteration: 45/49 ----Recurency: 2/5\n",
            "---Iteration: 46/49 ----Recurency: 2/5\n",
            "---Iteration: 47/49 ----Recurency: 2/5\n",
            "---Iteration: 48/49 ----Recurency: 2/5\n",
            "---Iteration: 49/49 ----Recurency: 2/5\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/36 ----Recurency: 3/5\n",
            "---Iteration: 2/36 ----Recurency: 3/5\n",
            "---Iteration: 3/36 ----Recurency: 3/5\n",
            "---Iteration: 4/36 ----Recurency: 3/5\n",
            "---Iteration: 5/36 ----Recurency: 3/5\n",
            "---Iteration: 6/36 ----Recurency: 3/5\n",
            "---Iteration: 7/36 ----Recurency: 3/5\n",
            "---Iteration: 8/36 ----Recurency: 3/5\n",
            "---Iteration: 9/36 ----Recurency: 3/5\n",
            "---Iteration: 10/36 ----Recurency: 3/5\n",
            "---Iteration: 11/36 ----Recurency: 3/5\n",
            "---Iteration: 12/36 ----Recurency: 3/5\n",
            "---Iteration: 13/36 ----Recurency: 3/5\n",
            "---Iteration: 14/36 ----Recurency: 3/5\n",
            "---Iteration: 15/36 ----Recurency: 3/5\n",
            "---Iteration: 16/36 ----Recurency: 3/5\n",
            "---Iteration: 17/36 ----Recurency: 3/5\n",
            "---Iteration: 18/36 ----Recurency: 3/5\n",
            "---Iteration: 19/36 ----Recurency: 3/5\n",
            "---Iteration: 20/36 ----Recurency: 3/5\n",
            "---Iteration: 21/36 ----Recurency: 3/5\n",
            "---Iteration: 22/36 ----Recurency: 3/5\n",
            "---Iteration: 23/36 ----Recurency: 3/5\n",
            "---Iteration: 24/36 ----Recurency: 3/5\n",
            "---Iteration: 25/36 ----Recurency: 3/5\n",
            "---Iteration: 26/36 ----Recurency: 3/5\n",
            "---Iteration: 27/36 ----Recurency: 3/5\n",
            "---Iteration: 28/36 ----Recurency: 3/5\n",
            "---Iteration: 29/36 ----Recurency: 3/5\n",
            "---Iteration: 30/36 ----Recurency: 3/5\n",
            "---Iteration: 31/36 ----Recurency: 3/5\n",
            "---Iteration: 32/36 ----Recurency: 3/5\n",
            "---Iteration: 33/36 ----Recurency: 3/5\n",
            "---Iteration: 34/36 ----Recurency: 3/5\n",
            "---Iteration: 35/36 ----Recurency: 3/5\n",
            "---Iteration: 36/36 ----Recurency: 3/5\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/25 ----Recurency: 4/5\n",
            "---Iteration: 2/25 ----Recurency: 4/5\n",
            "---Iteration: 3/25 ----Recurency: 4/5\n",
            "---Iteration: 4/25 ----Recurency: 4/5\n",
            "---Iteration: 5/25 ----Recurency: 4/5\n",
            "---Iteration: 6/25 ----Recurency: 4/5\n",
            "---Iteration: 7/25 ----Recurency: 4/5\n",
            "---Iteration: 8/25 ----Recurency: 4/5\n",
            "---Iteration: 9/25 ----Recurency: 4/5\n",
            "---Iteration: 10/25 ----Recurency: 4/5\n",
            "---Iteration: 11/25 ----Recurency: 4/5\n",
            "---Iteration: 12/25 ----Recurency: 4/5\n",
            "---Iteration: 13/25 ----Recurency: 4/5\n",
            "---Iteration: 14/25 ----Recurency: 4/5\n",
            "---Iteration: 15/25 ----Recurency: 4/5\n",
            "---Iteration: 16/25 ----Recurency: 4/5\n",
            "---Iteration: 17/25 ----Recurency: 4/5\n",
            "---Iteration: 18/25 ----Recurency: 4/5\n",
            "---Iteration: 19/25 ----Recurency: 4/5\n",
            "---Iteration: 20/25 ----Recurency: 4/5\n",
            "---Iteration: 21/25 ----Recurency: 4/5\n",
            "---Iteration: 22/25 ----Recurency: 4/5\n",
            "---Iteration: 23/25 ----Recurency: 4/5\n",
            "---Iteration: 24/25 ----Recurency: 4/5\n",
            "---Iteration: 25/25 ----Recurency: 4/5\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/16 ----Recurency: 5/5\n",
            "---Iteration: 2/16 ----Recurency: 5/5\n",
            "---Iteration: 3/16 ----Recurency: 5/5\n",
            "---Iteration: 4/16 ----Recurency: 5/5\n",
            "---Iteration: 5/16 ----Recurency: 5/5\n",
            "---Iteration: 6/16 ----Recurency: 5/5\n",
            "---Iteration: 7/16 ----Recurency: 5/5\n",
            "---Iteration: 8/16 ----Recurency: 5/5\n",
            "---Iteration: 9/16 ----Recurency: 5/5\n",
            "---Iteration: 10/16 ----Recurency: 5/5\n",
            "---Iteration: 11/16 ----Recurency: 5/5\n",
            "---Iteration: 12/16 ----Recurency: 5/5\n",
            "---Iteration: 13/16 ----Recurency: 5/5\n",
            "---Iteration: 14/16 ----Recurency: 5/5\n",
            "---Iteration: 15/16 ----Recurency: 5/5\n",
            "---Iteration: 16/16 ----Recurency: 5/5\n",
            "\n",
            "------------------ACHIEVED RESULTS------------------\n",
            "\n",
            "RESULT:             -19.87341814540811\n",
            "PARAMETER 1:        0.03174603174603177\n",
            "PARAMETER 2:        0.03174603174603177\n",
            "\n",
            "[[-15.029545861505717, -1.4285714285714288, -1.4285714285714288], [-18.18312885753426, -0.4761904761904763, -0.4761904761904763], [-19.622652810569264, -0.09523809523809523, -0.09523809523809523], [-19.622652810569264, -0.09523809523809523, -0.09523809523809523], [-19.87341814540811, 0.03174603174603177, 0.03174603174603177]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFYCAYAAABUA1WSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nToK9EEIIEeT+P9cFG4lQA9esAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4630818a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<__main__.optimizer object at 0x7f463059f5c0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hiQMEZChN7zT",
        "colab_type": "code",
        "outputId": "a27bc342-dbcf-413f-9231-9d8c0c3f07fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PySAu2dE8rlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Other:**"
      ]
    },
    {
      "metadata": {
        "id": "zeL7SA0PLWsc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def searchForFailed(yList):\n",
        "    changedRowList = []\n",
        "    for row in range (len(yList)):\n",
        "        if 0 in yList[row]:\n",
        "            changedRowList.append(row)\n",
        "    return changedRowList\n",
        "\n",
        "def returnFailedData(xList, yList, changedRowList):\n",
        "    xFailed = []\n",
        "    yFailed = []\n",
        "  \n",
        "    for row in changedRowList:\n",
        "        xFailed.append(xList[row])\n",
        "        yFailed.append(yList[row])\n",
        "    xFailed = np.array(xFailed)\n",
        "    yFailed = np.array(yFailed)\n",
        "    return xFailed, yFailed\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj27Oov0LYps",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def count_distribution(prediction):\n",
        "    #Distributions of argmins through all the predictions\n",
        "    i = 1\n",
        "    tab = [0] * 542\n",
        "    for a in prediction:\n",
        "        j = 0\n",
        "        for b in a:\n",
        "            if b < 1.0 : j = j + 1\n",
        "\n",
        "        #print (i, '. ', j, np.argmin(a))\n",
        "        tab[np.argmin(a)] += 1\n",
        "        i = i + 1\n",
        "\n",
        "    i = 0\n",
        "    distributed_array = []\n",
        "    for a in tab:\n",
        "        if a > 0 : \n",
        "            #print ('position', i, '\\targmin count', a)\n",
        "            distributed_array.append((i,a))\n",
        "        i += 1\n",
        "    create_plot(distributed_array)  \n",
        "    return distributed_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTmrDPbaLdDE",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def failsCount():\n",
        "    fala = 0\n",
        "    for i, a in enumerate(yTest):\n",
        "        j = 0\n",
        "        for k, b in enumerate(a):\n",
        "            if b < 1.0 : j += 1\n",
        "\n",
        "        if j > 0 : \n",
        "            print (i, '. ', j)\n",
        "        i = i + 1\n",
        "        fala += j\n",
        "    print (fala)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJvFgwwX4dXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Evaluation function\n",
        "\n",
        "def evaluation(additionalPredictions, refYsupervisor, predictions, verbose = False):\n",
        "  \n",
        "  lenght = len(refYsupervisor)\n",
        "\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);\n",
        "\n",
        "  predictionsTemp = predictions.copy()\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "  for i, a in enumerate(predictionsTemp):\n",
        "\n",
        "    if len(failPositions[i]) != 0:\n",
        "      for j in range(1 + additionalPredictions):\n",
        "        argmin = np.argmin(a)\n",
        "        predictionPositions[i].append(argmin)\n",
        "        predictionsTemp[i][argmin] = 1\n",
        "\n",
        "  predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(failPositions) != 0:\n",
        "      predictionHits[i] = count\n",
        "\n",
        "\n",
        "  failsCount = 0\n",
        "  hitsCount = 0\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "    j = 0\n",
        "\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "    failsCount += j\n",
        "    hitsCount += predictionHits[i]\n",
        "  result = hitsCount / failsCount * 100\n",
        "  print('Percentage of fails predicted', result, '%')\n",
        "  \n",
        "  if verbose == True:\n",
        "    for i in range(lenght):\n",
        "      print(i ,len(failPositions[i]), len(predictionPositions[i]), predictionHits[i], sep='\\t')\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdDLr2tEAeDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "812a0d6c-410e-40fd-cef9-fbbe840582cd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "class Metrics(Callback):\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
        "    val_targ = self.model.validation_data[1]\n",
        "    _val_f1 = f1_score(val_targ, val_predict)\n",
        "    _val_recall = recall_score(val_targ, val_predict)\n",
        "    _val_precision = precision_score(val_targ, val_predict)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "    return\n",
        "\n",
        "metrics = Metrics()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUqLiUzV82wE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**NEURAL NETWORK:**"
      ]
    },
    {
      "metadata": {
        "id": "G9WRpAqz9pmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data:"
      ]
    },
    {
      "metadata": {
        "id": "Slq936w_LgQN",
        "colab_type": "code",
        "outputId": "3e9fa3f5-db19-4489-ab20-49ab56dd8ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing dataset\n",
        "dataSetName = 'dataToML_full6.csv'\n",
        "\n",
        "dataset = pd.read_csv(dataSetName, index_col=False)\n",
        "\n",
        "#Check the first 5 rows of the dataset. \n",
        "dataset.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>...</th>\n",
              "      <th>1.530</th>\n",
              "      <th>1.531</th>\n",
              "      <th>1.532</th>\n",
              "      <th>1.533</th>\n",
              "      <th>1.534</th>\n",
              "      <th>1.535</th>\n",
              "      <th>1.536</th>\n",
              "      <th>1.537</th>\n",
              "      <th>1.538</th>\n",
              "      <th>1.539</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24281 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    1.530  1.531  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        1      1   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        1      1   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        1      1   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        1      1   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        1      1   \n",
              "\n",
              "   1.532  1.533  1.534  1.535  1.536  1.537  1.538  1.539  \n",
              "0      1      1      1      1      1      1      1      1  \n",
              "1      1      1      1      1      1      1      1      1  \n",
              "2      1      1      1      1      1      1      1      1  \n",
              "3      1      1      1      1      1      1      1      1  \n",
              "4      1      1      1      1      1      1      1      1  \n",
              "\n",
              "[5 rows x 24281 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "-FPw7Ysk2ic6",
        "colab_type": "code",
        "outputId": "20909a75-ee70-4adc-9d70-cc4a9fc08183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convertMinidataToML.csv  dataToML_full3.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2TS6_yWrL2Fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, 0:23739].values\n",
        "y = dataset.iloc[:, 23739:24281].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnPHXWnQL4NV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TCLVHfK7L6dt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state=77)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGWxKK3899YH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model definition:"
      ]
    },
    {
      "metadata": {
        "id": "4ETzd-5lL8R8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.backend import clear_session\n",
        "from keras.backend.tensorflow_backend import set_session  \n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback, EarlyStopping\n",
        "\n",
        "\n",
        "test = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2ssGUF3wkUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# One iteration NN\n",
        "\n",
        "if test:\n",
        "  from keras.backend.tensorflow_backend import set_session  \n",
        "\n",
        "  config = tf.ConfigProto()  \n",
        "  config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
        "  sess = tf.Session(config=config)  \n",
        "  set_session(sess)  # set this TensorFlow session as the default session for Keras.\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "\n",
        "  model.add(Dense(units = 542, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "\n",
        "  model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  model.fit(xTrain, yTrain, batch_size = 10, epochs = 2)\n",
        "\n",
        "  clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SNKBm1XlMARd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class roc_callback(Callback):\n",
        "    def __init__(self,training_data,validation_data):\n",
        "        self.x = training_data[0]\n",
        "        self.y = training_data[1]\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_pred = self.model.predict(self.x)\n",
        "        roc = roc_auc_score(self.y, y_pred)\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "def calculateNetwork(x, y):\n",
        "    inputUnits = 1372\n",
        "    firstLayerUnits = 10000\n",
        "    secondLayerUnits = 542\n",
        "    if not isinstance(inputUnits, (int)) or not isinstance(firstLayerUnits, (int)) or not isinstance(secondLayerUnits, (int)):\n",
        "        print(\"Enter correct input!\")\\\n",
        "\n",
        "    else:\n",
        "\n",
        "        config = tf.ConfigProto()  \n",
        "        config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
        "        sess = tf.Session(config=config)  \n",
        "        set_session(sess)\n",
        "        pBatchSize = 10\n",
        "        pEpochs = 4\n",
        "        #best pLearningRate = 0.85\n",
        "        pLearningRate = 0.25\n",
        "        #best momentum = 0.1\n",
        "        pMomentum = 0.25\n",
        "\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # Adding the input layer and the first hidden layer\n",
        "        model.add(Dense(inputUnits, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "        # Adding the second hidden layer\n",
        "        model.add(Dense(firstLayerUnits, activation = \"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "        # Adding the output layer\n",
        "        model.add(Dense(secondLayerUnits, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "\n",
        "        model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = pLearningRate, momentum = pMomentum), loss = 'binary_crossentropy')\n",
        "        model.fit(xTrain, yTrain,validation_data=(xTest, yTest), callbacks=[roc_callback(training_data=(xTrain, yTrain),validation_data=(xTest, yTest))], batch_size = pBatchSize, epochs = pEpochs)\n",
        "\n",
        "        predictions = model.predict(xTest)\n",
        "        evaluationResult = evaluation(15, yTest, predictions)\n",
        "        clear_session()\n",
        "        print('\\n')\n",
        "        return evaluationResult\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A22uR8UO2Jb8",
        "colab_type": "code",
        "outputId": "adaf9448-d86f-40c6-9230-9138f2e39538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1190
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(calculateNetwork(0.85, 0.1))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8208 samples, validate on 2053 samples\n",
            "Epoch 1/4\n",
            "8208/8208 [==============================] - 20s 2ms/step - loss: 0.0094 - val_loss: 0.0049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-184fffbe0cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculateNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-a316a80da217>\u001b[0m in \u001b[0;36mcalculateNetwork\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroc_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a316a80da217>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0my_pred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mroc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 120\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    325\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4DvM7zDGH4ES",
        "colab_type": "code",
        "outputId": "63a335d8-13fe-4e47-8b57-28a9ef5c36c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# This commant shows usage of Colab memory\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec  7 13:22:31 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    56W / 149W |   8334MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ssKmBP8MGF8",
        "colab_type": "code",
        "outputId": "65b06249-5bed-46c1-dd13-27d5a319b978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 43459
        }
      },
      "cell_type": "code",
      "source": [
        "if not test:\n",
        "  optimizer(calculateNetwork, 3 , [0.1, 1], minMax2=[0.1, 1],  split = 6, reduceSplit = True, searchMaximum = True)\n",
        "else:\n",
        "  print(\"Change 'test' variable to: False\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Iteration: 1/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.2424 - acc: 0.9558\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0622 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0393 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0311 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0270 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0246 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0230 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0220 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 2/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2205 - acc: 0.9609\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0537 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0349 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0282 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0249 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0230 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0210 - acc: 0.9970\n",
            "Percentage of fails predicted 30.0796812749004 %\n",
            "\n",
            "\n",
            "---Iteration: 3/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1884 - acc: 0.9651\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0434 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0298 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0251 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0227 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0214 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Percentage of fails predicted 29.830677290836654 %\n",
            "\n",
            "\n",
            "---Iteration: 4/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1548 - acc: 0.9726\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0350 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0257 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0225 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0209 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 5/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1213 - acc: 0.9754\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0272 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0220 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0202 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Percentage of fails predicted 29.880478087649404 %\n",
            "\n",
            "\n",
            "---Iteration: 6/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0863 - acc: 0.9763\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 30.0796812749004 %\n",
            "\n",
            "\n",
            "---Iteration: 7/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0828 - acc: 0.9788\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0467 - acc: 0.9969\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0471 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0472 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0475 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0479 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0478 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Percentage of fails predicted 0.0 %\n",
            "\n",
            "\n",
            "---Iteration: 8/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1316 - acc: 0.9789\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0305 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0235 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0211 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Percentage of fails predicted 30.02988047808765 %\n",
            "\n",
            "\n",
            "---Iteration: 9/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1170 - acc: 0.9801\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0276 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0203 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 10/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.1011 - acc: 0.9822\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0247 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0208 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Percentage of fails predicted 29.880478087649404 %\n",
            "\n",
            "\n",
            "---Iteration: 11/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0848 - acc: 0.9833\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0223 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Percentage of fails predicted 29.830677290836654 %\n",
            "\n",
            "\n",
            "---Iteration: 12/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0681 - acc: 0.9836\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 13/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0527 - acc: 0.9854\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0175 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0175 - acc: 0.9970\n",
            "Percentage of fails predicted 28.436254980079685 %\n",
            "\n",
            "\n",
            "---Iteration: 14/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0699 - acc: 0.9838\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0452 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0459 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0463 - acc: 0.9969\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0471 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9969\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0476 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0478 - acc: 0.9970\n",
            "Percentage of fails predicted 2.141434262948207 %\n",
            "\n",
            "\n",
            "---Iteration: 15/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0952 - acc: 0.9850\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0242 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 16/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0871 - acc: 0.9841\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0227 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 17/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0745 - acc: 0.9854\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0212 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 18/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0633 - acc: 0.9870\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.432270916334662 %\n",
            "\n",
            "\n",
            "---Iteration: 19/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0519 - acc: 0.9872\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.735059760956176 %\n",
            "\n",
            "\n",
            "---Iteration: 20/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0433 - acc: 0.9880\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 21/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0659 - acc: 0.9872\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0472 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0475 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Percentage of fails predicted 0.0 %\n",
            "\n",
            "\n",
            "---Iteration: 22/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0759 - acc: 0.9883\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0217 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 23/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0686 - acc: 0.9880\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0207 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 24/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0604 - acc: 0.9880\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.57768924302789 %\n",
            "\n",
            "\n",
            "---Iteration: 25/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0526 - acc: 0.9883\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.278884462151396 %\n",
            "\n",
            "\n",
            "---Iteration: 26/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0447 - acc: 0.9890\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 26.693227091633464 %\n",
            "\n",
            "\n",
            "---Iteration: 27/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0403 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 27.98804780876494 %\n",
            "\n",
            "\n",
            "---Iteration: 28/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0617 - acc: 0.9887\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0475 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Percentage of fails predicted 2.141434262948207 %\n",
            "\n",
            "\n",
            "---Iteration: 29/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0658 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 30/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0597 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.47808764940239 %\n",
            "\n",
            "\n",
            "---Iteration: 31/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0530 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.482071713147413 %\n",
            "\n",
            "\n",
            "---Iteration: 32/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0464 - acc: 0.9893\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.282868525896415 %\n",
            "\n",
            "\n",
            "---Iteration: 33/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0405 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.328685258964143 %\n",
            "\n",
            "\n",
            "---Iteration: 34/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0378 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 27.73904382470119 %\n",
            "\n",
            "\n",
            "---Iteration: 35/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0608 - acc: 0.9890\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0476 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0479 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0480 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0480 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Percentage of fails predicted 0.0 %\n",
            "\n",
            "\n",
            "---Iteration: 36/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0579 - acc: 0.9903\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 31.523904382470118 %\n",
            "\n",
            "\n",
            "---Iteration: 37/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0526 - acc: 0.9904\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.482071713147413 %\n",
            "\n",
            "\n",
            "---Iteration: 38/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0472 - acc: 0.9904\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.0796812749004 %\n",
            "\n",
            "\n",
            "---Iteration: 39/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0424 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.880478087649404 %\n",
            "\n",
            "\n",
            "---Iteration: 40/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0377 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.53187250996016 %\n",
            "\n",
            "\n",
            "---Iteration: 41/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0371 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 26.942231075697208 %\n",
            "\n",
            "\n",
            "---Iteration: 42/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Percentage of fails predicted 0.0 %\n",
            "\n",
            "\n",
            "---Iteration: 43/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0532 - acc: 0.9907\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.830677290836654 %\n",
            "\n",
            "\n",
            "---Iteration: 44/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9909\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 27.490039840637447 %\n",
            "\n",
            "\n",
            "---Iteration: 45/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0438 - acc: 0.9911\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.08366533864542 %\n",
            "\n",
            "\n",
            "---Iteration: 46/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0392 - acc: 0.9907\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.436254980079685 %\n",
            "\n",
            "\n",
            "---Iteration: 47/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0362 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 27.04183266932271 %\n",
            "\n",
            "\n",
            "---Iteration: 48/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0360 - acc: 0.9905\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Percentage of fails predicted 29.282868525896415 %\n",
            "\n",
            "\n",
            "---Iteration: 49/49 ----Recurency: 1/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0583 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0474 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0475 - acc: 0.9969\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0480 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0481 - acc: 0.9970\n",
            "Percentage of fails predicted 0.0 %\n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0678 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0208 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "---Iteration: 2/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 2ms/step - loss: 0.0672 - acc: 0.9880\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0205 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 3/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0634 - acc: 0.9894\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0203 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.57768924302789 %\n",
            "\n",
            "\n",
            "---Iteration: 4/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0618 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0201 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.53187250996016 %\n",
            "\n",
            "\n",
            "---Iteration: 5/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0610 - acc: 0.9893\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.776892430278885 %\n",
            "\n",
            "\n",
            "---Iteration: 6/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0591 - acc: 0.9894\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.229083665338646 %\n",
            "\n",
            "\n",
            "---Iteration: 7/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0635 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0204 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0188 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.278884462151396 %\n",
            "\n",
            "\n",
            "---Iteration: 8/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 2ms/step - loss: 0.0626 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0202 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "---Iteration: 9/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0614 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.834661354581677 %\n",
            "\n",
            "\n",
            "---Iteration: 10/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0589 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.627490039840637 %\n",
            "\n",
            "\n",
            "---Iteration: 11/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0581 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 31.175298804780876 %\n",
            "\n",
            "\n",
            "---Iteration: 12/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 2ms/step - loss: 0.0568 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.378486055776893 %\n",
            "\n",
            "\n",
            "---Iteration: 13/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0616 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0201 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.332669322709165 %\n",
            "\n",
            "\n",
            "---Iteration: 14/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.880478087649404 %\n",
            "\n",
            "\n",
            "---Iteration: 15/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0588 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "---Iteration: 16/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0568 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.378486055776893 %\n",
            "\n",
            "\n",
            "---Iteration: 17/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0559 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.428286852589643 %\n",
            "\n",
            "\n",
            "---Iteration: 18/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0547 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.58167330677291 %\n",
            "\n",
            "\n",
            "---Iteration: 19/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0605 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.432270916334662 %\n",
            "\n",
            "\n",
            "---Iteration: 20/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 2ms/step - loss: 0.0582 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "---Iteration: 21/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0568 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.278884462151396 %\n",
            "\n",
            "\n",
            "---Iteration: 22/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0551 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.52788844621514 %\n",
            "\n",
            "\n",
            "---Iteration: 23/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0544 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.731075697211157 %\n",
            "\n",
            "\n",
            "---Iteration: 24/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0516 - acc: 0.9904\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.934262948207174 %\n",
            "\n",
            "\n",
            "---Iteration: 25/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0569 - acc: 0.9901\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.830677290836654 %\n",
            "\n",
            "\n",
            "---Iteration: 26/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0555 - acc: 0.9905\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "---Iteration: 27/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0544 - acc: 0.9904\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.282868525896415 %\n",
            "\n",
            "\n",
            "---Iteration: 28/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0531 - acc: 0.9901\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.63545816733068 %\n",
            "\n",
            "\n",
            "---Iteration: 29/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0516 - acc: 0.9904\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.984063745019924 %\n",
            "\n",
            "\n",
            "---Iteration: 30/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0498 - acc: 0.9907\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.282868525896415 %\n",
            "\n",
            "\n",
            "---Iteration: 31/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0542 - acc: 0.9907\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.731075697211157 %\n",
            "\n",
            "\n",
            "---Iteration: 32/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0531 - acc: 0.9905\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0193 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.482071713147413 %\n",
            "\n",
            "\n",
            "---Iteration: 33/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0523 - acc: 0.9903\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0192 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.681274900398407 %\n",
            "\n",
            "\n",
            "---Iteration: 34/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0504 - acc: 0.9910\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0191 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.934262948207174 %\n",
            "\n",
            "\n",
            "---Iteration: 35/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0496 - acc: 0.9906\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.428286852589643 %\n",
            "\n",
            "\n",
            "---Iteration: 36/36 ----Recurency: 2/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0493 - acc: 0.9903\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.834661354581677 %\n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0627 - acc: 0.9893\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0202 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "---Iteration: 2/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0637 - acc: 0.9884\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0201 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0187 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.780876494023907 %\n",
            "\n",
            "\n",
            "---Iteration: 3/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0596 - acc: 0.9901\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.53187250996016 %\n",
            "\n",
            "\n",
            "---Iteration: 4/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0601 - acc: 0.9889\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.830677290836654 %\n",
            "\n",
            "\n",
            "---Iteration: 5/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0586 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "---Iteration: 6/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0622 - acc: 0.9886\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0200 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0182 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.681274900398407 %\n",
            "\n",
            "\n",
            "---Iteration: 7/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0606 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.53187250996016 %\n",
            "\n",
            "\n",
            "---Iteration: 8/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0599 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.02988047808765 %\n",
            "\n",
            "\n",
            "---Iteration: 9/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0586 - acc: 0.9894\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.0796812749004 %\n",
            "\n",
            "\n",
            "---Iteration: 10/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0579 - acc: 0.9893\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "---Iteration: 11/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0591 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.229083665338646 %\n",
            "\n",
            "\n",
            "---Iteration: 12/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0583 - acc: 0.9902\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.382470119521916 %\n",
            "\n",
            "\n",
            "---Iteration: 13/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0566 - acc: 0.9908\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.432270916334662 %\n",
            "\n",
            "\n",
            "---Iteration: 14/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0579 - acc: 0.9890\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.332669322709165 %\n",
            "\n",
            "\n",
            "---Iteration: 15/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0568 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.68525896414343 %\n",
            "\n",
            "\n",
            "---Iteration: 16/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0589 - acc: 0.9896\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.1792828685259 %\n",
            "\n",
            "\n",
            "---Iteration: 17/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0571 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.378486055776893 %\n",
            "\n",
            "\n",
            "---Iteration: 18/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0568 - acc: 0.9894\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "---Iteration: 19/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0574 - acc: 0.9888\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.23306772908367 %\n",
            "\n",
            "\n",
            "---Iteration: 20/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0549 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.328685258964143 %\n",
            "\n",
            "\n",
            "---Iteration: 21/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0569 - acc: 0.9902\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.53187250996016 %\n",
            "\n",
            "\n",
            "---Iteration: 22/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0562 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.08366533864542 %\n",
            "\n",
            "\n",
            "---Iteration: 23/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0562 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.02988047808765 %\n",
            "\n",
            "\n",
            "---Iteration: 24/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0554 - acc: 0.9896\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 25/25 ----Recurency: 3/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0543 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0183 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.229083665338646 %\n",
            "\n",
            "\n",
            "---------------------------------------------------------\n",
            "\n",
            "---Iteration: 1/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0603 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0186 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.278884462151396 %\n",
            "\n",
            "\n",
            "---Iteration: 2/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0588 - acc: 0.9902\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.984063745019924 %\n",
            "\n",
            "\n",
            "---Iteration: 3/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0589 - acc: 0.9893\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.23306772908367 %\n",
            "\n",
            "\n",
            "---Iteration: 4/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0587 - acc: 0.9892\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.229083665338646 %\n",
            "\n",
            "\n",
            "---Iteration: 5/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0585 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.87649402390438 %\n",
            "\n",
            "\n",
            "---Iteration: 6/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0585 - acc: 0.9895\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.282868525896415 %\n",
            "\n",
            "\n",
            "---Iteration: 7/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0582 - acc: 0.9891\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.378486055776893 %\n",
            "\n",
            "\n",
            "---Iteration: 8/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0569 - acc: 0.9900\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.382470119521916 %\n",
            "\n",
            "\n",
            "---Iteration: 9/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0578 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.681274900398407 %\n",
            "\n",
            "\n",
            "---Iteration: 10/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0576 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0185 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 30.57768924302789 %\n",
            "\n",
            "\n",
            "---Iteration: 11/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0569 - acc: 0.9897\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0181 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.731075697211157 %\n",
            "\n",
            "\n",
            "---Iteration: 12/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0561 - acc: 0.9899\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "---Iteration: 13/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0572 - acc: 0.9896\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.731075697211157 %\n",
            "\n",
            "\n",
            "---Iteration: 14/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0569 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0196 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "---Iteration: 15/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0561 - acc: 0.9898\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 29.03386454183267 %\n",
            "\n",
            "\n",
            "---Iteration: 16/16 ----Recurency: 4/4\n",
            "Epoch 1/8\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.0554 - acc: 0.9902\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0195 - acc: 0.9970\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0184 - acc: 0.9970\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0180 - acc: 0.9970\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0177 - acc: 0.9970\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0176 - acc: 0.9970\n",
            "Percentage of fails predicted 28.68525896414343 %\n",
            "\n",
            "\n",
            "\n",
            "------------------ACHIEVED RESULTS------------------\n",
            "\n",
            "RESULT:             31.523904382470118\n",
            "PARAMETER 1:        0.85\n",
            "PARAMETER 2:        0.1\n",
            "\n",
            "[[31.523904382470118, 0.85, 0.1], [31.175298804780876, 0.7599999999999999, 0.21000000000000002], [30.378486055776893, 0.7899999999999999, 0.19], [30.87649402390438, 0.78, 0.16999999999999998]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6b58cba5f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yUDJAaVLb55J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "globalCounter = 0\n",
        "def calculateNetwork2(parameters):\n",
        "    global globalCounter\n",
        "    print(\"Iteration: {}\".format(globalCounter))\n",
        "\n",
        "    globalCounter += 1\n",
        "    x = parameters[0]\n",
        "    y = parameters[1]\n",
        "    inputUnits = 1372\n",
        "    firstLayerUnits = 2000\n",
        "    secondLayerUnits = 542\n",
        "    if not isinstance(inputUnits, (int)) or not isinstance(firstLayerUnits, (int)) or not isinstance(secondLayerUnits, (int)):\n",
        "        print(\"Enter correct input!\")\\\n",
        "\n",
        "    else:\n",
        "\n",
        "        config = tf.ConfigProto()  \n",
        "        config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
        "        sess = tf.Session(config=config)  \n",
        "        set_session(sess)\n",
        "        pBatchSize = 10\n",
        "        pEpochs = 2\n",
        "        #best pLearningRate = 0.85\n",
        "        pLearningRate = x\n",
        "        #best momentum = 0.1\n",
        "        pMomentum = y\n",
        "\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # Adding the input layer and the first hidden layer\n",
        "        model.add(Dense(inputUnits, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "        # Adding the second hidden layer\n",
        "        model.add(Dense(firstLayerUnits, activation = \"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "        # Adding the output layer\n",
        "        model.add(Dense(secondLayerUnits, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "\n",
        "        model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = pLearningRate, momentum = pMomentum), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        model.fit(xTrain, yTrain, batch_size = pBatchSize, epochs = pEpochs)\n",
        "\n",
        "        predictions = model.predict(xReduced)\n",
        "        evaluationResult = evaluation(15, yReduced, predictions)\n",
        "        clear_session()\n",
        "        print('\\n')\n",
        "        return evaluationResult\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-E8l7gDblnJ",
        "colab_type": "code",
        "outputId": "31d9a759-9868-483f-ac46-aa8b3df754d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5487
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "#optimizer(exampleFunction, 12 , [-10,10], minMax2=[-10, 10],  split = 10, reduceSplit = True, searchMaximum = False)\n",
        "# x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
        "x0 = np.array([0.1,0.1])\n",
        "globalCounter = 0\n",
        "res = minimize(calculateNetwork2, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True})\n",
        "print(res.x) \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 3s 3ms/step - loss: 0.2375 - acc: 0.9596\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0621 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "Iteration: 1\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2342 - acc: 0.9568\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0593 - acc: 0.9970\n",
            "Percentage of fails predicted 29.133466135458168 %\n",
            "\n",
            "\n",
            "Iteration: 2\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2406 - acc: 0.9573\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0621 - acc: 0.9970\n",
            "Percentage of fails predicted 29.183266932270918 %\n",
            "\n",
            "\n",
            "Iteration: 3\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2349 - acc: 0.9569\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0593 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "Iteration: 4\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2441 - acc: 0.9534\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0619 - acc: 0.9970\n",
            "Percentage of fails predicted 29.183266932270918 %\n",
            "\n",
            "\n",
            "Iteration: 5\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2408 - acc: 0.9539\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0606 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "Iteration: 6\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2408 - acc: 0.9537\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0610 - acc: 0.9970\n",
            "Percentage of fails predicted 30.677290836653388 %\n",
            "\n",
            "\n",
            "Iteration: 7\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2338 - acc: 0.9598\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9970\n",
            "Percentage of fails predicted 29.63147410358566 %\n",
            "\n",
            "\n",
            "Iteration: 8\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2373 - acc: 0.9578\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0606 - acc: 0.9970\n",
            "Percentage of fails predicted 29.23306772908367 %\n",
            "\n",
            "\n",
            "Iteration: 9\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2370 - acc: 0.9569\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0597 - acc: 0.9970\n",
            "Percentage of fails predicted 30.976095617529882 %\n",
            "\n",
            "\n",
            "Iteration: 10\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2355 - acc: 0.9584\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0606 - acc: 0.9970\n",
            "Percentage of fails predicted 28.784860557768926 %\n",
            "\n",
            "\n",
            "Iteration: 11\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2335 - acc: 0.9579\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0595 - acc: 0.9970\n",
            "Percentage of fails predicted 29.183266932270918 %\n",
            "\n",
            "\n",
            "Iteration: 12\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2324 - acc: 0.9606\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0598 - acc: 0.9970\n",
            "Percentage of fails predicted 29.133466135458168 %\n",
            "\n",
            "\n",
            "Iteration: 13\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2348 - acc: 0.9585\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0605 - acc: 0.9970\n",
            "Percentage of fails predicted 29.731075697211157 %\n",
            "\n",
            "\n",
            "Iteration: 14\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2312 - acc: 0.9591\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0593 - acc: 0.9970\n",
            "Percentage of fails predicted 29.780876494023907 %\n",
            "\n",
            "\n",
            "Iteration: 15\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2353 - acc: 0.9581\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0604 - acc: 0.9970\n",
            "Percentage of fails predicted 30.328685258964143 %\n",
            "\n",
            "\n",
            "Iteration: 16\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2378 - acc: 0.9573\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0604 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "Iteration: 17\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2397 - acc: 0.9554\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0608 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "Iteration: 18\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2308 - acc: 0.9604\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0597 - acc: 0.9970\n",
            "Percentage of fails predicted 29.93027888446215 %\n",
            "\n",
            "\n",
            "Iteration: 19\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2356 - acc: 0.9571\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0599 - acc: 0.9970\n",
            "Percentage of fails predicted 29.08366533864542 %\n",
            "\n",
            "\n",
            "Iteration: 20\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2368 - acc: 0.9565\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9970\n",
            "Percentage of fails predicted 30.1792828685259 %\n",
            "\n",
            "\n",
            "Iteration: 21\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2372 - acc: 0.9568\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0605 - acc: 0.9970\n",
            "Percentage of fails predicted 29.9800796812749 %\n",
            "\n",
            "\n",
            "Iteration: 22\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2353 - acc: 0.9580\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0601 - acc: 0.9970\n",
            "Percentage of fails predicted 30.0796812749004 %\n",
            "\n",
            "\n",
            "Iteration: 23\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2375 - acc: 0.9559\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9970\n",
            "Percentage of fails predicted 30.627490039840637 %\n",
            "\n",
            "\n",
            "Iteration: 24\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2369 - acc: 0.9595\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0612 - acc: 0.9970\n",
            "Percentage of fails predicted 30.776892430278885 %\n",
            "\n",
            "\n",
            "Iteration: 25\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2326 - acc: 0.9597\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0597 - acc: 0.9970\n",
            "Percentage of fails predicted 30.87649402390438 %\n",
            "\n",
            "\n",
            "Iteration: 26\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2347 - acc: 0.9581\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9970\n",
            "Percentage of fails predicted 30.12948207171315 %\n",
            "\n",
            "\n",
            "Iteration: 27\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2359 - acc: 0.9578\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0605 - acc: 0.9970\n",
            "Percentage of fails predicted 28.386454183266935 %\n",
            "\n",
            "\n",
            "Iteration: 28\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2323 - acc: 0.9600\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0599 - acc: 0.9970\n",
            "Percentage of fails predicted 29.332669322709165 %\n",
            "\n",
            "\n",
            "Iteration: 29\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2371 - acc: 0.9552\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.0600 - acc: 0.9970\n",
            "Percentage of fails predicted 30.02988047808765 %\n",
            "\n",
            "\n",
            "Iteration: 30\n",
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 2s 2ms/step - loss: 0.2403 - acc: 0.9552\n",
            "Epoch 2/2\n",
            " 820/1012 [=======================>......] - ETA: 0s - loss: 0.0640 - acc: 0.9970"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-5cd01efb0440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mglobalCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculateNetwork2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'xtol'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'disp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    589\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mone2np1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                         \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                         \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-050442f5b220>\u001b[0m in \u001b[0;36mcalculateNetwork2\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxReduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}