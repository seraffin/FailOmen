{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workingNN_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraffin/FailOmen/blob/master/Wojtek/workingNN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4GnGAWK8qX-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "362783d3-6e01-4e88-dbad-d086368bbac4"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "izxs0AbFRAmO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Utilities:**"
      ]
    },
    {
      "metadata": {
        "id": "7wNeM8QPQusb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def searchForFailed(yList):\n",
        "  changedRowList = []\n",
        "  for row in range (len(yList)):\n",
        "    if 0 in yList[row]:\n",
        "      changedRowList.append(row)\n",
        "  return changedRowList\n",
        "\n",
        "def returnFailedData(xList, yList, changedRowList):\n",
        "  xFailed = []\n",
        "  yFailed = []\n",
        "  \n",
        "  for row in changedRowList:\n",
        "    xFailed.append(xList[row])\n",
        "    yFailed.append(yList[row])\n",
        "  xFailed = np.array(xFailed)\n",
        "  yFailed = np.array(yFailed)\n",
        "  return xFailed, yFailed\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8licy-LM9BB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_distribution(prediction):\n",
        "  #Distributions of argmins through all the predictions\n",
        "  i = 1\n",
        "  tab = [0] * 542\n",
        "  for a in predictions:\n",
        "    j = 0\n",
        "    for b in a:\n",
        "      if b < 1.0 : j = j + 1\n",
        "\n",
        "    #print (i, '. ', j, np.argmin(a))\n",
        "    tab[np.argmin(a)] += 1\n",
        "    i = i + 1\n",
        "\n",
        "  i = 0\n",
        "  distributed_array = []\n",
        "  for a in tab:\n",
        "    if a > 0 : \n",
        "      #print ('position', i, '\\targmin count', a)\n",
        "      distributed_array.append((i,a))\n",
        "    i += 1\n",
        "  create_plot(distributed_array)  \n",
        "  return distributed_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jA7Iz8inM_1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_plot(x_data, y_data=0):\n",
        "  import matplotlib.pyplot as plt\n",
        "  if y_data == 0:  \n",
        "    unzip = list(zip(*x_data))\n",
        "    x_data, y_data = unzip[0],unzip[1]\n",
        "  plt.bar(x_data, y_data,width=10)\n",
        "  plt.xlabel(\"test no\")\n",
        "  plt.ylabel(\"how many times test was predicted as the best to use\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cxgyuOYqNECI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def failsCount():\n",
        "  fala = 0\n",
        "  for i, a in enumerate(yTest):\n",
        "    j = 0\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "    if j > 0 : \n",
        "      print (i, '. ', j)\n",
        "    i = i + 1\n",
        "    fala += j\n",
        "  print (fala)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Idg1pThSNo1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(additionalPredictions, refYsupervisor):\n",
        "  \n",
        "  lenght = len(refYsupervisor)\n",
        "\n",
        "  failPositions = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "\n",
        "    for j, b in enumerate(a):\n",
        "      if b == 0 : failPositions[i].append(j);\n",
        "\n",
        "  predictionsTemp = predictions.copy()\n",
        "  predictionPositions = [[] for y in range(lenght)]\n",
        "\n",
        "\n",
        "  for i, a in enumerate(predictionsTemp):\n",
        "\n",
        "    if len(failPositions[i]) != 0:\n",
        "      for j in range(len(failPositions[i]) + additionalPredictions):\n",
        "        argmin = np.argmin(a)\n",
        "        predictionPositions[i].append(argmin)\n",
        "        predictionsTemp[i][argmin] = 1\n",
        "\n",
        "  predictionHits = [[] for y in range(lenght)]\n",
        "\n",
        "  for i, a in enumerate(failPositions):\n",
        "    count = 0\n",
        "    for j, b in enumerate(a):\n",
        "\n",
        "\n",
        "      for c in predictionPositions[i]:\n",
        "  #      predictionHits[i].append(predictions[i][c].copy())\n",
        "  #      print(predictions[i][c])\n",
        "  #      print(predictions[i][c])\n",
        "  #      print (b, c)\n",
        "        if c == b : count += 1\n",
        "\n",
        "    if len(failPositions) != 0:\n",
        "      predictionHits[i].insert(0,count)\n",
        "\n",
        "\n",
        "  failsCount = 0\n",
        "  hitsCount = 0\n",
        "  for i, a in enumerate(refYsupervisor):\n",
        "    j = 0\n",
        "\n",
        "    for k, b in enumerate(a):\n",
        "      if b < 1.0 : j += 1\n",
        "\n",
        "  #  if j > 0 :\n",
        "  #    print (i, '.', j, predictionHits[i])\n",
        "\n",
        "\n",
        "    failsCount += j\n",
        "    hitsCount += predictionHits[i][0]\n",
        "    \n",
        "  percFailsPredicted = hitsCount / failsCount * 100\n",
        "  print('Percentage of fails predicted', hitsCount / failsCount * 100, '%')\n",
        "  return percFailsPredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27aN-0qvRTbB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check if runtime is on GPU:**"
      ]
    },
    {
      "metadata": {
        "id": "6bL5_HKrqmDJ",
        "colab_type": "code",
        "outputId": "7539c749-d636-47e5-f237-0ec6bda66a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "--bcUjUMRbAp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Import dataset:**"
      ]
    },
    {
      "metadata": {
        "id": "x1fErHE2qmmv",
        "colab_type": "code",
        "outputId": "ffbaf02f-ba77-4434-b418-9bd1fe28c0b4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c53b0707-a146-4c19-a2ad-0817b93cfa61\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c53b0707-a146-4c19-a2ad-0817b93cfa61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataToML_newConcept.csv to dataToML_newConcept.csv\n",
            "User uploaded file \"dataToML_newConcept.csv\" with length 234154858 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LYINvf7bO6JM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63a3d643-2049-4a57-ec2d-32b35b22b700"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataToML_newConcept.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sxNkj80iqotw",
        "colab_type": "code",
        "outputId": "7535791a-bb33-4bbc-e184-42ca842909d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing dataset\n",
        "dataset = pd.read_csv('dataToML_newConcept.csv', index_col=False)\n",
        "\n",
        "#Check the first 5 rows of the dataset. \n",
        "dataset.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>24272</th>\n",
              "      <th>24273</th>\n",
              "      <th>24274</th>\n",
              "      <th>24275</th>\n",
              "      <th>24276</th>\n",
              "      <th>24277</th>\n",
              "      <th>24278</th>\n",
              "      <th>24279</th>\n",
              "      <th>24280</th>\n",
              "      <th>24281</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24281 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1  2  3  4  5  6  7  8  9  10  ...    24272  24273  24274  24275  24276  \\\n",
              "0  1  1  1  1  1  1  1  1  1   1  ...        1      1      1      1      1   \n",
              "1  1  1  1  1  1  1  1  1  1   1  ...        1      1      1      1      1   \n",
              "2  1  1  1  1  1  1  1  1  1   1  ...        1      1      1      1      1   \n",
              "3  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "4  0  0  0  0  0  0  0  0  0   0  ...        1      1      1      1      1   \n",
              "\n",
              "   24277  24278  24279  24280  24281  \n",
              "0      1      1      1      1      1  \n",
              "1      1      1      1      1      1  \n",
              "2      1      1      1      1      1  \n",
              "3      1      1      1      1      1  \n",
              "4      1      1      1      1      1  \n",
              "\n",
              "[5 rows x 24281 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "lib5WXDc_av6",
        "colab_type": "code",
        "outputId": "06ae5e7c-67e8-4bcb-da6e-cc91ea4b34ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convertDataToML.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B1p1y_UoRtq_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Assign values for building Neural Network:**"
      ]
    },
    {
      "metadata": {
        "id": "vhs63LrXqq3Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, 0:23739].values\n",
        "y = dataset.iloc[:, 23739:24281].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0s4ZY3eUV9qZ",
        "colab_type": "code",
        "outputId": "4ee25d68-d02d-445d-84bc-7f7cd7e51cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(x))\n",
        "print(len(y))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4818\n",
            "4818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qVNLyXEJWqax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(Optional) Reduce data just to this with included failed test:**"
      ]
    },
    {
      "metadata": {
        "id": "n2jSwTvKVI35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xReduced, yReduced = returnFailedData(x, y, searchForFailed(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYoH1N-CWYtJ",
        "colab_type": "code",
        "outputId": "1cf545f3-a3de-4981-8063-8f08ec87e5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(xReduced))\n",
        "print(len(yReduced))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "712\n",
            "712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e9eGKhlER4sg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split valuses to Test/Train:**\n",
        "\n",
        "test_size = 0.2   -->  Train = 80% / Test = 20%"
      ]
    },
    {
      "metadata": {
        "id": "6VXIzxxzqtN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(xReduced, yReduced, test_size = 0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8qq0SlHZaxk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Defining Neural Network:**"
      ]
    },
    {
      "metadata": {
        "id": "vwTF-qc0qvL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the output layer\n",
        "model.add(Dense(units = 542, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YV8uKm-rZxkr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Running Builded NN:**"
      ]
    },
    {
      "metadata": {
        "id": "2MVYSHRNqys9",
        "colab_type": "code",
        "outputId": "0ce03323-7be3-4bf8-cb4b-f8a8b2b66dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = 0.01, momentum = 0.4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        " \n",
        "model.fit(xTrain, yTrain, batch_size = 10, epochs = 2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "569/569 [==============================] - 1s 2ms/step - loss: 0.6728 - acc: 0.6999\n",
            "Epoch 2/2\n",
            "569/569 [==============================] - 1s 1ms/step - loss: 0.6722 - acc: 0.7042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc556c7390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "2lxrBPnyi1mZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3600
        },
        "outputId": "6fe8c154-0b0f-427c-97cb-0ad3dba20793"
      },
      "cell_type": "code",
      "source": [
        "predictionArray = []\n",
        "for i in range(1, 5):\n",
        "  pBatchSize = 10\n",
        "  pEpochs = 2\n",
        "  pLearningRate = 0.01 + float(\"0.0{}\".format(i))\n",
        "  pMomentum = 0.01 + float(\"0.0{}\".format(i))\n",
        "  print (pLearningRate)\n",
        "  print(pMomentum)\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  \n",
        "  \n",
        "  # Adding the input layer and the first hidden layer\n",
        "  model.add(Dense(6070, activation=\"sigmoid\", input_dim=23739, kernel_initializer=\"uniform\")) # TRY smaller input_dim value or less neurons\n",
        "  # Adding the second hidden layer\n",
        "  model.add(Dense(2000 * i, activation = \"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "  # Adding the output layer\n",
        "  model.add(Dense(542, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "  \n",
        "  \n",
        "  model.compile(optimizer = tf.train.MomentumOptimizer(learning_rate = pLearningRate, momentum = pMomentum), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  model.fit(xTrain, yTrain, batch_size = pBatchSize, epochs = pEpochs)\n",
        "  \n",
        "  predictions = model.predict(xReduced)\n",
        "  \n",
        "  predictionArray.append(evaluation(15, yReduced))\n",
        "  print(\"\\n ----------------------------------------------------------\\n\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02\n",
            "0.02\n",
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [23739,6070] and type float\n\t [[{{node dense_12/kernel/Momentum/Initializer/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,6070] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-3d7f440edc18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxReduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2482\u001b[0m                               **self.session_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [23739,6070] and type float\n\t [[node dense_12/kernel/Momentum/Initializer/zeros (defined at /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:676)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,6070] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'dense_12/kernel/Momentum/Initializer/zeros', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-62-3d7f440edc18>\", line 23, in <module>\n    model.fit(xTrain, yTrain, batch_size = pBatchSize, epochs = pEpochs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 1002, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 676, in get_updates\n    grads, global_step=self.iterations)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/momentum.py\", line 77, in _create_slots\n    self._zeros_slot(v, \"momentum\", self._name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py\", line 101, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1563, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2979, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [23739,6070] and type float\n\t [[node dense_12/kernel/Momentum/Initializer/zeros (defined at /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:676)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23739,6070] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0y-rDkOtbUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19af7b1e-e80c-45fa-e826-44ffcc0393d4"
      },
      "cell_type": "code",
      "source": [
        "for i in range(1, 4):\n",
        "  print(i)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QU8y471plXB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eef14be5-75ff-4210-e989-052dc00c50ea"
      },
      "cell_type": "code",
      "source": [
        "print(predictionArray)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.4432809773123907, 2.4432809773123907, 2.4432809773123907, 2.4432809773123907]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oP5xfxu9aBQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check network correctness:**"
      ]
    },
    {
      "metadata": {
        "id": "0UKZ7Kglq0vN",
        "colab_type": "code",
        "outputId": "27e4da92-b20f-4716-f036-85a3893a9c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "lossTest, accTest = model.evaluate(xTest, yTest)\n",
        "\n",
        "print('Test accuracy:', accTest)\n",
        "print('Test loss:', lossTest)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 0s 2ms/step\n",
            "Test accuracy: 0.8423476802719223\n",
            "Test loss: 0.6464445245015872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d7hcQeoXOsah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#choose one\n",
        "\n",
        "# predictions = model.predict(xTest)\n",
        "predictions = model.predict(xReduced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6JzfkH7q1ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "7c39918e-d60c-4048-e568-5f60dd6d98f0"
      },
      "cell_type": "code",
      "source": [
        "#Distributions of argmins through all the predictions\n",
        "distribution_array = count_distribution(predictions)\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efc5115d278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LQ5xIqonkCx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1edbf7d0-e46c-48f8-c15e-bc5f942380c7"
      },
      "cell_type": "code",
      "source": [
        "evaluation(15, yReduced)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of fails predicted 3.5776614310645725 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5776614310645725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}